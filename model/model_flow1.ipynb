{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e56eb7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from flow import ResidualCouplingBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a020209a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualCouplingBlock(\n",
       "  (flows): ModuleList(\n",
       "    (0): ResidualCouplingLayer(\n",
       "      (pre): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (enc): WN(\n",
       "        (in_layers): ModuleList(\n",
       "          (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (2): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (3): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (res_skip_layers): ModuleList(\n",
       "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (2): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (post): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (1): Flip()\n",
       "    (2): ResidualCouplingLayer(\n",
       "      (pre): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (enc): WN(\n",
       "        (in_layers): ModuleList(\n",
       "          (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (2): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (3): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (res_skip_layers): ModuleList(\n",
       "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (2): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (post): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Flip()\n",
       "    (4): ResidualCouplingLayer(\n",
       "      (pre): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (enc): WN(\n",
       "        (in_layers): ModuleList(\n",
       "          (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (2): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (3): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (res_skip_layers): ModuleList(\n",
       "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (2): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (post): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (5): Flip()\n",
       "    (6): ResidualCouplingLayer(\n",
       "      (pre): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (enc): WN(\n",
       "        (in_layers): ModuleList(\n",
       "          (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (2): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (3): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (res_skip_layers): ModuleList(\n",
       "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (2): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (post): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (7): Flip()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_channels = 128\n",
    "hidden_channels = 256\n",
    "gin_channels = 0\n",
    "flow = ResidualCouplingBlock(inter_channels, hidden_channels, 5, 1, 4, gin_channels=gin_channels)\n",
    "flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4dea024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 100]) tensor([0., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 128, 100)\n",
    "x_mask = torch.ones(x.shape[0], 1, 1)\n",
    "y, logdet = flow(x, x_mask=x_mask)\n",
    "print(y.shape, logdet)\n",
    "\n",
    "x_recon = flow(y, x_mask=x_mask, reverse=True)\n",
    "x == x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fddeb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from flow import ResidualCouplingBlock\n",
    "from cbhg import CBHG\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.out_dim = out_dim\n",
    "        self.z_dim = out_dim if out_dim % 2 == 0 else out_dim + 1\n",
    "        self.encoder = CBHG(in_dim, self.z_dim)\n",
    "        self.decoder = ResidualCouplingBlock(self.z_dim, 256, 5, 1, 4, gin_channels=0)\n",
    "        \n",
    "    def get_loss(self, z, logdet):\n",
    "        dim = z.size(1) * z.size(2)\n",
    "        nll = -(torch.sum(-0.5 * (np.log(2*np.pi) + z**2), dim=[1, 2]) + logdet)\n",
    "        loss = torch.mean(nll / dim)\n",
    "        return loss\n",
    "            \n",
    "    def forward(self, x, y):\n",
    "        # x : (b, c, t)\n",
    "        # y : (b, c, t)\n",
    "        \n",
    "        if y.shape[1] != self.z_dim:\n",
    "            y = F.pad(y, (0, 0, 0, 1))\n",
    "        \n",
    "        y_mask = torch.ones(y.shape[0], 1, 1).to(x.device)\n",
    "        z, logdet = self.decoder(y, y_mask)\n",
    "        flow_loss = self.get_loss(z, logdet)\n",
    "        \n",
    "        z_pred = self.encoder(x)\n",
    "        reg_loss = F.l1_loss(z_pred, z.detach())\n",
    "        \n",
    "        data = {'flow_loss': flow_loss,\n",
    "                'reg_loss': reg_loss,\n",
    "                'total_loss': flow_loss + reg_loss}\n",
    "        return data\n",
    "    \n",
    "    def inference(self, x):\n",
    "        z = self.encoder(x)\n",
    "        y_mask = torch.ones(z.shape[0], 1, 1).to(x.device)\n",
    "        y = self.decoder(z, y_mask, reverse=True)\n",
    "        y = y[:, :self.out_dim]\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d979360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (encoder): CBHG(\n",
       "    (conv_bank): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConstantPad1d(padding=(0, 0), value=0.0)\n",
       "        (1): Conv1d(8, 256, kernel_size=(1,), stride=(1,))\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConstantPad1d(padding=(0, 1), value=0.0)\n",
       "        (1): Conv1d(8, 256, kernel_size=(2,), stride=(1,))\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConstantPad1d(padding=(1, 1), value=0.0)\n",
       "        (1): Conv1d(8, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConstantPad1d(padding=(1, 2), value=0.0)\n",
       "        (1): Conv1d(8, 256, kernel_size=(4,), stride=(1,))\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConstantPad1d(padding=(2, 2), value=0.0)\n",
       "        (1): Conv1d(8, 256, kernel_size=(5,), stride=(1,))\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): ConstantPad1d(padding=(2, 3), value=0.0)\n",
       "        (1): Conv1d(8, 256, kernel_size=(6,), stride=(1,))\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): ConstantPad1d(padding=(3, 3), value=0.0)\n",
       "        (1): Conv1d(8, 256, kernel_size=(7,), stride=(1,))\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): ConstantPad1d(padding=(3, 4), value=0.0)\n",
       "        (1): Conv1d(8, 256, kernel_size=(8,), stride=(1,))\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (max_pool): Sequential(\n",
       "      (0): ConstantPad1d(padding=(0, 1), value=0.0)\n",
       "      (1): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (projections): Sequential(\n",
       "      (0): Conv1d(2048, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv1d(512, 8, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (highways): ModuleList(\n",
       "      (0): Linear(in_features=8, out_features=512, bias=True)\n",
       "      (1): HighwayNet(\n",
       "        (projection): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (gate): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): HighwayNet(\n",
       "        (projection): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (gate): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): HighwayNet(\n",
       "        (projection): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (gate): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (4): HighwayNet(\n",
       "        (projection): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (gate): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gru): GRU(512, 256, batch_first=True, bidirectional=True)\n",
       "    (output): Linear(in_features=512, out_features=66, bias=True)\n",
       "  )\n",
       "  (decoder): ResidualCouplingBlock(\n",
       "    (flows): ModuleList(\n",
       "      (0): ResidualCouplingLayer(\n",
       "        (pre): Conv1d(33, 256, kernel_size=(1,), stride=(1,))\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (post): Conv1d(256, 33, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): Flip()\n",
       "      (2): ResidualCouplingLayer(\n",
       "        (pre): Conv1d(33, 256, kernel_size=(1,), stride=(1,))\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (post): Conv1d(256, 33, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): Flip()\n",
       "      (4): ResidualCouplingLayer(\n",
       "        (pre): Conv1d(33, 256, kernel_size=(1,), stride=(1,))\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (post): Conv1d(256, 33, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (5): Flip()\n",
       "      (6): ResidualCouplingLayer(\n",
       "        (pre): Conv1d(33, 256, kernel_size=(1,), stride=(1,))\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (post): Conv1d(256, 33, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (7): Flip()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(8, 65)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c338bc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flow_loss': tensor(1.4175, grad_fn=<MeanBackward0>),\n",
       " 'reg_loss': tensor(0.7934, grad_fn=<L1LossBackward0>),\n",
       " 'total_loss': tensor(2.2109, grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 8, 100)\n",
    "y = torch.randn(2, 65, 100)\n",
    "model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64da0406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0604, -0.0547, -0.0443,  ..., -0.0587, -0.0729, -0.0769],\n",
       "         [-0.0002,  0.0245,  0.0423,  ...,  0.0720,  0.0446,  0.0189],\n",
       "         [-0.0461, -0.0383, -0.0422,  ..., -0.0041,  0.0062,  0.0218],\n",
       "         ...,\n",
       "         [ 0.0605,  0.0596,  0.0820,  ...,  0.0508,  0.0610,  0.0498],\n",
       "         [ 0.0673,  0.0502,  0.0612,  ...,  0.0469,  0.0535,  0.0508],\n",
       "         [ 0.0708,  0.1026,  0.1132,  ...,  0.1429,  0.1508,  0.1366]],\n",
       "\n",
       "        [[-0.0429, -0.0666, -0.0842,  ..., -0.0367, -0.0663, -0.0831],\n",
       "         [ 0.0107,  0.0226, -0.0137,  ...,  0.0703,  0.0957,  0.0437],\n",
       "         [-0.0184, -0.0129, -0.0038,  ...,  0.0316,  0.0266,  0.0097],\n",
       "         ...,\n",
       "         [ 0.0764,  0.0643,  0.0632,  ...,  0.0952,  0.0859,  0.0814],\n",
       "         [ 0.0228,  0.0371,  0.0323,  ...,  0.0541,  0.0735,  0.0603],\n",
       "         [ 0.0952,  0.1177,  0.1132,  ...,  0.1255,  0.1221,  0.0855]]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inference(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0fd1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75984606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a74f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.0",
   "language": "python",
   "name": "torch2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
