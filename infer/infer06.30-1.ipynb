{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78297a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd99c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 30 20:05:41 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| 30%   31C    P8    13W / 230W |    779MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000    Off  | 00000000:1C:00.0 Off |                  Off |\n",
      "| 30%   29C    P8    15W / 230W |   5482MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A5000    Off  | 00000000:1D:00.0 Off |                  Off |\n",
      "| 30%   41C    P2   192W / 230W |   8687MiB / 24564MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A5000    Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 30%   39C    P2    63W / 230W |   9256MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA RTX A5000    Off  | 00000000:89:00.0 Off |                  Off |\n",
      "| 30%   48C    P2    93W / 230W |   8675MiB / 24564MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA RTX A5000    Off  | 00000000:8A:00.0 Off |                  Off |\n",
      "| 30%   57C    P2   197W / 230W |   8687MiB / 24564MiB |     97%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA RTX A5000    Off  | 00000000:8B:00.0 Off |                  Off |\n",
      "| 30%   28C    P8    18W / 230W |    749MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA RTX A5000    Off  | 00000000:8C:00.0 Off |                  Off |\n",
      "| 30%   40C    P2    61W / 230W |   4903MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A   3105924      C   ...onda3/envs/ste/bin/python      771MiB |\n",
      "|    1   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A   2665624      C   ...hyun/anaconda3/bin/python     2657MiB |\n",
      "|    1   N/A  N/A   2668046      C   ...hyun/anaconda3/bin/python     2817MiB |\n",
      "|    2   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A   3564506      C   ...onda3/envs/ste/bin/python     8679MiB |\n",
      "|    3   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A   2561159      C   ByteSep Inference                 569MiB |\n",
      "|    3   N/A  N/A   3724080      C   ...onda3/envs/ste/bin/python     8679MiB |\n",
      "|    4   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A   3248740      C   ...onda3/envs/ste/bin/python     8667MiB |\n",
      "|    5   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A   3355402      C   ...onda3/envs/ste/bin/python     8679MiB |\n",
      "|    6   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    6   N/A  N/A   1538568      C   ...3/envs/bytesep/bin/python      741MiB |\n",
      "|    7   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A   2972606      C   ...3/envs/bytesep/bin/python     4895MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f7414",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205b3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 16\n",
    "n_outputs = 61\n",
    "n_frames = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85ba9cc",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1783a54",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'speechbrain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_transformer_vae\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Model\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/wav2face/model/model_transformer_vae.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Encoder\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspeechbrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlobes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mECAPA_TDNN\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ECAPA_TDNN\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_dim, h_dim, out_dim, z_dim):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speechbrain'"
     ]
    }
   ],
   "source": [
    "from model.model_transformer_vae import Model\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Model\n",
    "model = Model(in_dim=n_mels, h_dim=512, out_dim=n_outputs, z_dim=2)\n",
    "model = model.to(device)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce852cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_dir = '/data/scpark/save/lips/train06.30-1/'\n",
    "!ls -lt $load_dir\n",
    "\n",
    "path = load_dir + 'save_' + str(47000)\n",
    "checkpoint = torch.load(path, map_location=torch.device('cpu'))    \n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ea0993",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158aaabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "wav_file = '/Storage/speech/tts/kaist-audio-book/wav/남1_동화1/1181.wav'\n",
    "offset = 0\n",
    "duration = None\n",
    "wav, _ = librosa.load(wav_file, sr=24000, offset=offset, duration=duration, res_type='polyphase')\n",
    "wav = wav / np.max(np.abs(wav))\n",
    "mel = librosa.feature.melspectrogram(y=wav, sr=24000, n_fft=2048, hop_length=800, win_length=2048, n_mels=n_mels)\n",
    "mel = np.log10(mel + 1e-5)    \n",
    "mel_tensor = torch.Tensor(mel).unsqueeze(0).to(device)\n",
    "print(mel.shape, mel_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd13bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model.inference(mel_tensor)\n",
    "\n",
    "plt.figure(figsize=[18, 3])\n",
    "librosa.display.specshow(pred[0].data.cpu().numpy(), cmap='magma')\n",
    "\n",
    "plt.figure(figsize=[18, 3])\n",
    "librosa.display.specshow(mel_tensor[0].data.cpu().numpy(), cmap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6ffab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedac976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5399d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c4637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste2",
   "language": "python",
   "name": "ste2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
