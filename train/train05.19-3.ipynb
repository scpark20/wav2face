{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79d0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6665403e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 19 17:49:33 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| 30%   27C    P8    13W / 230W |   1433MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000    Off  | 00000000:1C:00.0 Off |                  Off |\n",
      "| 30%   55C    P2   103W / 230W |  20131MiB / 24564MiB |     17%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A5000    Off  | 00000000:1D:00.0 Off |                  Off |\n",
      "| 30%   49C    P2   120W / 230W |  15005MiB / 24564MiB |     27%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A5000    Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 30%   51C    P2   145W / 230W |  16397MiB / 24564MiB |     29%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA RTX A5000    Off  | 00000000:89:00.0 Off |                  Off |\n",
      "| 30%   59C    P2   144W / 230W |  20161MiB / 24564MiB |     78%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA RTX A5000    Off  | 00000000:8A:00.0 Off |                  Off |\n",
      "| 30%   54C    P2   128W / 230W |  16159MiB / 24564MiB |     20%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA RTX A5000    Off  | 00000000:8B:00.0 Off |                  Off |\n",
      "| 30%   27C    P8    17W / 230W |      5MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA RTX A5000    Off  | 00000000:8C:00.0 Off |                  Off |\n",
      "| 30%   42C    P2    94W / 230W |   3461MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A   3439958      C   ...3/envs/vspeech/bin/python     1425MiB |\n",
      "|    1   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A   1792411      C   ...3/envs/vspeech/bin/python    20123MiB |\n",
      "|    2   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A   1985994      C   ...3/envs/vspeech/bin/python    14997MiB |\n",
      "|    3   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A   4160782      C   ...3/envs/vspeech/bin/python    16389MiB |\n",
      "|    4   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A    172531      C   ...3/envs/vspeech/bin/python    20153MiB |\n",
      "|    5   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A    299985      C   ...3/envs/vspeech/bin/python    16151MiB |\n",
      "|    6   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A   3023930      C   ...nda3/envs/ste2/bin/python     3453MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee05e12",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb821737",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 8\n",
    "n_outputs = 61\n",
    "n_frames = 400\n",
    "sr = 24000\n",
    "fps = 30\n",
    "train_csv_files = ['/Storage/speech/face/rvh_visme_1_iPhone_30fps.csv',\n",
    "                  '/Storage/speech/face/rvh_visme_2_iPhone_30fps.csv',\n",
    "                  '/Storage/speech/face/rvh_visme_3_iPhone_30fps.csv']\n",
    "train_wav_files = ['/Storage/speech/face/rvh_visme_1_iPhone.wav',\n",
    "                 '/Storage/speech/face/rvh_visme_2_iPhone.wav',\n",
    "                 '/Storage/speech/face/rvh_visme_3_iPhone.wav']\n",
    "\n",
    "test_csv_files = ['/Storage/speech/face/rvh_visme_4_iPhone_30fps.csv']\n",
    "test_wav_files = ['/Storage/speech/face/rvh_visme_4_iPhone.wav']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c54e68",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cedcf798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from model.model_vqvae import Model\n",
    "from utils.util import *\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Model\n",
    "model = Model(in_dim=n_mels, out_dim=n_outputs, K=8, latent_dim=256)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31748b8c",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "998d7f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "-rw-rw-r-- 1 scpark scpark 0  5월 19 17:50 events.out.tfevents.1684486205.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark 0  5월 19 17:49 events.out.tfevents.1684486191.GPUSVR01\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lips/train05.19-3/'\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model, _, optimizer = load(save_dir, 2207, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a8aa62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset : 22042\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f42e0438f70>\n",
      "test dataset : 7725\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f42414b36a0>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from data.dataset import LipsDataset, Collate\n",
    "\n",
    "dataset = LipsDataset(train_wav_files, train_csv_files, n_frames, n_mels=n_mels, sr=sr, fps=fps, perturb=True)\n",
    "print('train dataset :', len(dataset))\n",
    "train_loader = torch.utils.data.DataLoader(dataset, num_workers=1, shuffle=True, batch_size=8, \n",
    "                                           collate_fn=Collate(n_frames, n_mels))\n",
    "print(train_loader)\n",
    "\n",
    "dataset = LipsDataset(test_wav_files, test_csv_files, n_frames, n_mels=n_mels, sr=sr, fps=fps, perturb=False)\n",
    "print('test dataset :', len(dataset))\n",
    "test_loader = torch.utils.data.DataLoader(dataset, num_workers=1, shuffle=True, batch_size=8,\n",
    "                                           collate_fn=Collate(n_frames, n_mels))\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03238ce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test : 0 2.061098575592041\n",
      "test : 1 2.0616862773895264\n",
      "test : 2 2.060452461242676\n",
      "test : 3 2.0599799156188965\n",
      "test : 4 2.0610709190368652\n",
      "test : 5 2.0619049072265625\n",
      "test : 6 2.0609099864959717\n",
      "test : 7 2.061115264892578\n",
      "test : 8 2.061785936355591\n",
      "test : 9 2.0606460571289062\n",
      "test_loss : 2.061065196990967\n",
      "saved /data/scpark/save/lips/train05.19-3/save_0\n",
      "1\n",
      "auto_encoding_loss 0.08060593158006668\n",
      "commit_loss 0.0005267133237794042\n",
      "zi_prediction_loss 2.044222593307495\n",
      "1 2.1253552436828613\n",
      "2\n",
      "auto_encoding_loss 0.07014196366071701\n",
      "commit_loss 0.0005122608854435384\n",
      "zi_prediction_loss 2.027386426925659\n",
      "2 2.0980405807495117\n",
      "3\n",
      "auto_encoding_loss 0.06299041956663132\n",
      "commit_loss 0.000519749999511987\n",
      "zi_prediction_loss 1.9960893392562866\n",
      "3 2.0595993995666504\n",
      "4\n",
      "auto_encoding_loss 0.05753957852721214\n",
      "commit_loss 0.0005416167550720274\n",
      "zi_prediction_loss 1.9759162664413452\n",
      "4 2.0339975357055664\n",
      "5\n",
      "auto_encoding_loss 0.057844214141368866\n",
      "commit_loss 0.0005728437099605799\n",
      "zi_prediction_loss 1.9637670516967773\n",
      "5 2.022184133529663\n",
      "6\n",
      "auto_encoding_loss 0.05040980130434036\n",
      "commit_loss 0.0005629633087664843\n",
      "zi_prediction_loss 1.9427517652511597\n",
      "6 1.9937245845794678\n",
      "7\n",
      "auto_encoding_loss 0.04168357327580452\n",
      "commit_loss 0.0005823253304697573\n",
      "zi_prediction_loss 1.9203896522521973\n",
      "7 1.9626555442810059\n",
      "8\n",
      "auto_encoding_loss 0.037724100053310394\n",
      "commit_loss 0.0006026621558703482\n",
      "zi_prediction_loss 1.8897417783737183\n",
      "8 1.9280685186386108\n",
      "9\n",
      "auto_encoding_loss 0.034883737564086914\n",
      "commit_loss 0.0006543893832713366\n",
      "zi_prediction_loss 1.8505247831344604\n",
      "9 1.8860628604888916\n",
      "10\n",
      "auto_encoding_loss 0.03394285961985588\n",
      "commit_loss 0.0006825870950706303\n",
      "zi_prediction_loss 1.8047680854797363\n",
      "10 1.8393934965133667\n",
      "11\n",
      "auto_encoding_loss 0.02964104898273945\n",
      "commit_loss 0.0006784260622225702\n",
      "zi_prediction_loss 1.7614288330078125\n",
      "11 1.791748285293579\n",
      "12\n",
      "auto_encoding_loss 0.028274264186620712\n",
      "commit_loss 0.0007194126956164837\n",
      "zi_prediction_loss 1.7353591918945312\n",
      "12 1.7643529176712036\n",
      "13\n",
      "auto_encoding_loss 0.02859889715909958\n",
      "commit_loss 0.0007684644660912454\n",
      "zi_prediction_loss 1.6782499551773071\n",
      "13 1.7076172828674316\n",
      "14\n",
      "auto_encoding_loss 0.03020414523780346\n",
      "commit_loss 0.0007230271003209054\n",
      "zi_prediction_loss 1.7825148105621338\n",
      "14 1.8134419918060303\n",
      "15\n",
      "auto_encoding_loss 0.031416092067956924\n",
      "commit_loss 0.0006882762536406517\n",
      "zi_prediction_loss 1.8585597276687622\n",
      "15 1.8906641006469727\n",
      "16\n",
      "auto_encoding_loss 0.02973376214504242\n",
      "commit_loss 0.0007251673960126936\n",
      "zi_prediction_loss 1.8090617656707764\n",
      "16 1.8395206928253174\n",
      "17\n",
      "auto_encoding_loss 0.028689304366707802\n",
      "commit_loss 0.0008115579257719219\n",
      "zi_prediction_loss 1.8195816278457642\n",
      "17 1.8490824699401855\n",
      "18\n",
      "auto_encoding_loss 0.03218410164117813\n",
      "commit_loss 0.0008380282670259476\n",
      "zi_prediction_loss 1.8340365886688232\n",
      "18 1.8670587539672852\n",
      "19\n",
      "auto_encoding_loss 0.025572236627340317\n",
      "commit_loss 0.0008883043192327023\n",
      "zi_prediction_loss 1.7920715808868408\n",
      "19 1.818532109260559\n",
      "20\n",
      "auto_encoding_loss 0.02861034870147705\n",
      "commit_loss 0.000949941691942513\n",
      "zi_prediction_loss 1.7796261310577393\n",
      "20 1.8091864585876465\n",
      "21\n",
      "auto_encoding_loss 0.027045750990509987\n",
      "commit_loss 0.0009619509219191968\n",
      "zi_prediction_loss 1.7765188217163086\n",
      "21 1.8045265674591064\n",
      "22\n",
      "auto_encoding_loss 0.03210426867008209\n",
      "commit_loss 0.0009946445934474468\n",
      "zi_prediction_loss 1.7958042621612549\n",
      "22 1.8289031982421875\n",
      "23\n",
      "auto_encoding_loss 0.02755080908536911\n",
      "commit_loss 0.0011797776678577065\n",
      "zi_prediction_loss 1.6772503852844238\n",
      "23 1.7059810161590576\n",
      "24\n",
      "auto_encoding_loss 0.026082398369908333\n",
      "commit_loss 0.0012799985706806183\n",
      "zi_prediction_loss 1.6151221990585327\n",
      "24 1.6424845457077026\n",
      "25\n",
      "auto_encoding_loss 0.026169372722506523\n",
      "commit_loss 0.001297574257478118\n",
      "zi_prediction_loss 1.625052809715271\n",
      "25 1.652519702911377\n",
      "26\n",
      "auto_encoding_loss 0.027045562863349915\n",
      "commit_loss 0.0015213261358439922\n",
      "zi_prediction_loss 1.5509103536605835\n",
      "26 1.5794771909713745\n",
      "27\n",
      "auto_encoding_loss 0.025865938514471054\n",
      "commit_loss 0.001685503637418151\n",
      "zi_prediction_loss 1.5346488952636719\n",
      "27 1.5622003078460693\n",
      "28\n",
      "auto_encoding_loss 0.02767118811607361\n",
      "commit_loss 0.0018030646024271846\n",
      "zi_prediction_loss 1.4932583570480347\n",
      "28 1.5227326154708862\n",
      "29\n",
      "auto_encoding_loss 0.023968400433659554\n",
      "commit_loss 0.001955555286258459\n",
      "zi_prediction_loss 1.5291110277175903\n",
      "29 1.5550349950790405\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "isnan = False\n",
    "while True:\n",
    "    if isnan:\n",
    "        break\n",
    "    for batch in train_loader:\n",
    "        inputs = batch['inputs'].transpose(1, 2).to(device)\n",
    "        targets = batch['outputs'].transpose(1, 2).to(device)\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs, targets)\n",
    "        \n",
    "        print(step)\n",
    "        loss = 0\n",
    "        for key in outputs.keys():\n",
    "            if 'loss' in key:\n",
    "                loss += outputs[key]\n",
    "                print(key, outputs[key].item())\n",
    "        if torch.isnan(loss):\n",
    "            isnan = True\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(step, loss.item())\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            writer.add_scalar('train_loss', loss.item(), step)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            display.clear_output()\n",
    "            \n",
    "            losses = []\n",
    "            for i, batch in enumerate(test_loader):\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                    \n",
    "                inputs = batch['inputs'].transpose(1, 2).to(device)\n",
    "                targets = batch['outputs'].transpose(1, 2).to(device)\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs, targets)\n",
    "                    \n",
    "                loss = 0\n",
    "                for key in outputs.keys():\n",
    "                    if 'loss' in key:\n",
    "                        loss += outputs[key]\n",
    "                print('test :', i, loss.item())\n",
    "                losses.append(loss)        \n",
    "            \n",
    "            test_loss = torch.stack(losses).mean().item()\n",
    "            print('test_loss :', test_loss)\n",
    "            writer.add_scalar('test_loss', test_loss, step)\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            save(save_dir, step, model, None, optimizer)\n",
    "    \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f9a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98af31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839fa05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e8ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste2",
   "language": "python",
   "name": "ste2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
