{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79d0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6665403e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  7 22:46:15 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.199.02   Driver Version: 470.199.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   62C    P0   301W / 300W |  32593MiB / 80994MiB |    100%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  Off  | 00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    42W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  Off  | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    72W / 300W |  39421MiB / 80994MiB |     92%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  Off  | 00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   53C    P0   212W / 300W |  54981MiB / 80994MiB |     90%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100 80G...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   64C    P0   299W / 300W |  31432MiB / 80994MiB |    100%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100 80G...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   64C    P0   300W / 300W |  31432MiB / 80994MiB |     94%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100 80G...  Off  | 00000000:8B:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    43W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100 80G...  Off  | 00000000:8C:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    42W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    0   N/A  N/A   3091454      C   ...a3/envs/scpark/bin/python     1155MiB |\n",
      "|    0   N/A  N/A   3097830      C   ...a3/envs/scpark/bin/python    15703MiB |\n",
      "|    0   N/A  N/A   3101124      C   ...a3/envs/scpark/bin/python    15697MiB |\n",
      "|    1   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    2   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    2   N/A  N/A   3876253      C   ...a3/envs/scpark/bin/python    39383MiB |\n",
      "|    3   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    3   N/A  N/A   3916614      C   ...a3/envs/scpark/bin/python    54943MiB |\n",
      "|    4   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    4   N/A  N/A   3100828      C   ...a3/envs/scpark/bin/python    15697MiB |\n",
      "|    4   N/A  N/A   3100981      C   ...a3/envs/scpark/bin/python    15697MiB |\n",
      "|    5   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    5   N/A  N/A   3100534      C   ...a3/envs/scpark/bin/python    15697MiB |\n",
      "|    5   N/A  N/A   3100678      C   ...a3/envs/scpark/bin/python    15697MiB |\n",
      "|    6   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    7   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee05e12",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb821737",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 768\n",
    "n_outputs = 61\n",
    "n_frames = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c54e68",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedcf798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from model.model_transformer_reg import Model\n",
    "from utils.util import *\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Model\n",
    "model = Model(in_dim=n_mels, h_dim=512, out_dim=n_outputs)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31748b8c",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998d7f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1043672\r\n",
      "-rw-rw-r-- 1 scpark scpark       131  8월  7 22:45 events.out.tfevents.1691415822.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark 534355839  8월  7 22:44 save_5\r\n",
      "-rw-rw-r-- 1 scpark scpark 534355839  8월  7 22:44 save_0\r\n",
      "-rw-rw-r-- 1 scpark scpark         0  8월  7 22:02 events.out.tfevents.1691413338.GPUSVR11\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lips/train08.08-7/'\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model, _, optimizer = load(save_dir, 133000, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d7b3c",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8aa62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_20_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_21_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_30_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_31_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_40_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_50_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_51_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_52_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_6_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_7_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_9_iPhone_raw.npy\n",
      "16 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data.arkit_dataset import LipsDataset, CombinedDataset, CombinedCollate\n",
    "\n",
    "root_dir = '/data/speech/digital_human/preprocessed/yehunHwang'\n",
    "files = sorted([os.path.join(root_dir, file) for file in os.listdir(root_dir) if 'ARKit' in file])\n",
    "print(len(files))\n",
    "\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    dataset = LipsDataset(file, n_mels, n_frames, perturb=False)\n",
    "    if '_1_' in file:\n",
    "        test_datasets.append(dataset)\n",
    "    else:\n",
    "        train_datasets.append(dataset)\n",
    "print(len(train_datasets), len(test_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc7cac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(CombinedDataset(train_datasets), \n",
    "                                           num_workers=16, shuffle=True, batch_size=32, collate_fn=CombinedCollate())\n",
    "test_loader = torch.utils.data.DataLoader(CombinedDataset(test_datasets), \n",
    "                                          num_workers=10, shuffle=True, batch_size=10, collate_fn=CombinedCollate())\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795a6367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 22:46:31 | INFO | fairseq.tasks.hubert_pretraining | current directory is /home/scpark/projects/wav2face\n",
      "2023-08-07 22:46:31 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'metadata', 'fine_tuning': False, 'labels': ['km'], 'label_dir': 'label', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
      "2023-08-07 22:46:31 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import fairseq\n",
    "from torchaudio.transforms import Resample\n",
    "\n",
    "resample = Resample(24000, 16000)\n",
    "\n",
    "ckpt_path = \"/Storage/speech/pretrained/contentvec/checkpoint_best_legacy_500.pt\"\n",
    "hubert, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
    "hubert = hubert[0]\n",
    "hubert = hubert.to(device)\n",
    "hubert.eval()\n",
    "\n",
    "def get_hubert_feature(wav):\n",
    "    with torch.no_grad():\n",
    "        # (b, t, c)\n",
    "        wav = resample(torch.Tensor(wav)).to(device)\n",
    "        feature = hubert.extract_features(wav, output_layer=12)[0]\n",
    "        return feature.transpose(1, 2)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03238ce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test : 0 0.8581734895706177\n",
      "test : 1 0.855551540851593\n",
      "test : 2 0.8561782836914062\n",
      "test : 3 0.8568066954612732\n",
      "test : 4 0.8555034399032593\n",
      "test : 5 0.8561365604400635\n",
      "test : 6 0.856967031955719\n",
      "test : 7 0.8577532172203064\n",
      "test : 8 0.856499969959259\n",
      "test : 9 0.856006383895874\n",
      "test_loss : 0.8565576672554016\n",
      "saved /data/scpark/save/lips/train08.08-7/save_0\n",
      "1\n",
      "loss 0.8370347023010254\n",
      "1 0.8370347023010254\n",
      "2\n",
      "loss 0.5336255431175232\n",
      "2 0.5336255431175232\n",
      "3\n",
      "loss 0.37246325612068176\n",
      "3 0.37246325612068176\n",
      "4\n",
      "loss 0.2531784176826477\n",
      "4 0.2531784176826477\n",
      "5\n",
      "loss 0.18763545155525208\n",
      "5 0.18763545155525208\n",
      "6\n",
      "loss 0.1846725046634674\n",
      "6 0.1846725046634674\n",
      "7\n",
      "loss 0.19174574315547943\n",
      "7 0.19174574315547943\n",
      "8\n",
      "loss 0.1748339831829071\n",
      "8 0.1748339831829071\n",
      "9\n",
      "loss 0.1574152112007141\n",
      "9 0.1574152112007141\n",
      "10\n",
      "loss 0.1478520631790161\n",
      "10 0.1478520631790161\n",
      "11\n",
      "loss 0.14165367186069489\n",
      "11 0.14165367186069489\n",
      "12\n",
      "loss 0.13705889880657196\n",
      "12 0.13705889880657196\n",
      "13\n",
      "loss 0.13575588166713715\n",
      "13 0.13575588166713715\n",
      "14\n",
      "loss 0.1348552107810974\n",
      "14 0.1348552107810974\n",
      "15\n",
      "loss 0.12516264617443085\n",
      "15 0.12516264617443085\n",
      "16\n",
      "loss 0.1284739375114441\n",
      "16 0.1284739375114441\n",
      "17\n",
      "loss 0.12220270186662674\n",
      "17 0.12220270186662674\n",
      "18\n",
      "loss 0.12409128993749619\n",
      "18 0.12409128993749619\n",
      "19\n",
      "loss 0.12066776305437088\n",
      "19 0.12066776305437088\n",
      "20\n",
      "loss 0.11970598995685577\n",
      "20 0.11970598995685577\n",
      "21\n",
      "loss 0.11889592558145523\n",
      "21 0.11889592558145523\n",
      "22\n",
      "loss 0.11818473786115646\n",
      "22 0.11818473786115646\n",
      "23\n",
      "loss 0.11797475069761276\n",
      "23 0.11797475069761276\n",
      "24\n",
      "loss 0.11457312107086182\n",
      "24 0.11457312107086182\n",
      "25\n",
      "loss 0.11350855976343155\n",
      "25 0.11350855976343155\n",
      "26\n",
      "loss 0.11153842508792877\n",
      "26 0.11153842508792877\n",
      "27\n",
      "loss 0.11377913504838943\n",
      "27 0.11377913504838943\n",
      "28\n",
      "loss 0.1154087483882904\n",
      "28 0.1154087483882904\n",
      "29\n",
      "loss 0.10935746878385544\n",
      "29 0.10935746878385544\n",
      "30\n",
      "loss 0.11475875973701477\n",
      "30 0.11475875973701477\n",
      "31\n",
      "loss 0.10776348412036896\n",
      "31 0.10776348412036896\n",
      "32\n",
      "loss 0.10955911874771118\n",
      "32 0.10955911874771118\n",
      "33\n",
      "loss 0.10530063509941101\n",
      "33 0.10530063509941101\n",
      "34\n",
      "loss 0.10807053744792938\n",
      "34 0.10807053744792938\n",
      "35\n",
      "loss 0.1081651821732521\n",
      "35 0.1081651821732521\n",
      "36\n",
      "loss 0.10552680492401123\n",
      "36 0.10552680492401123\n",
      "37\n",
      "loss 0.10541276633739471\n",
      "37 0.10541276633739471\n",
      "38\n",
      "loss 0.1065663993358612\n",
      "38 0.1065663993358612\n",
      "39\n",
      "loss 0.10424197465181351\n",
      "39 0.10424197465181351\n",
      "40\n",
      "loss 0.10295484215021133\n",
      "40 0.10295484215021133\n",
      "41\n",
      "loss 0.10224083811044693\n",
      "41 0.10224083811044693\n",
      "42\n",
      "loss 0.10560830682516098\n",
      "42 0.10560830682516098\n",
      "43\n",
      "loss 0.10130023956298828\n",
      "43 0.10130023956298828\n",
      "44\n",
      "loss 0.10447146743535995\n",
      "44 0.10447146743535995\n",
      "45\n",
      "loss 0.10240256041288376\n",
      "45 0.10240256041288376\n",
      "46\n",
      "loss 0.10376017540693283\n",
      "46 0.10376017540693283\n",
      "47\n",
      "loss 0.10178087651729584\n",
      "47 0.10178087651729584\n",
      "48\n",
      "loss 0.10074172914028168\n",
      "48 0.10074172914028168\n",
      "49\n",
      "loss 0.09764014184474945\n",
      "49 0.09764014184474945\n",
      "50\n",
      "loss 0.10008038580417633\n",
      "50 0.10008038580417633\n",
      "51\n",
      "loss 0.09895429760217667\n",
      "51 0.09895429760217667\n",
      "52\n",
      "loss 0.098951555788517\n",
      "52 0.098951555788517\n",
      "53\n",
      "loss 0.09631479531526566\n",
      "53 0.09631479531526566\n",
      "54\n",
      "loss 0.10079430043697357\n",
      "54 0.10079430043697357\n",
      "55\n",
      "loss 0.099991075694561\n",
      "55 0.099991075694561\n",
      "56\n",
      "loss 0.1053176000714302\n",
      "56 0.1053176000714302\n",
      "57\n",
      "loss 0.0985211655497551\n",
      "57 0.0985211655497551\n",
      "58\n",
      "loss 0.10396023839712143\n",
      "58 0.10396023839712143\n",
      "59\n",
      "loss 0.09463252872228622\n",
      "59 0.09463252872228622\n",
      "60\n",
      "loss 0.101296067237854\n",
      "60 0.101296067237854\n",
      "61\n",
      "loss 0.1012553796172142\n",
      "61 0.1012553796172142\n",
      "62\n",
      "loss 0.09991157054901123\n",
      "62 0.09991157054901123\n",
      "63\n",
      "loss 0.1030900627374649\n",
      "63 0.1030900627374649\n",
      "64\n",
      "loss 0.09671895205974579\n",
      "64 0.09671895205974579\n",
      "65\n",
      "loss 0.09889888763427734\n",
      "65 0.09889888763427734\n",
      "66\n",
      "loss 0.09529148042201996\n",
      "66 0.09529148042201996\n",
      "67\n",
      "loss 0.09510231763124466\n",
      "67 0.09510231763124466\n",
      "68\n",
      "loss 0.10089807957410812\n",
      "68 0.10089807957410812\n",
      "69\n",
      "loss 0.09588634967803955\n",
      "69 0.09588634967803955\n",
      "70\n",
      "loss 0.09471754729747772\n",
      "70 0.09471754729747772\n",
      "71\n",
      "loss 0.10047154873609543\n",
      "71 0.10047154873609543\n",
      "72\n",
      "loss 0.10030975192785263\n",
      "72 0.10030975192785263\n",
      "73\n",
      "loss 0.09600042551755905\n",
      "73 0.09600042551755905\n",
      "74\n",
      "loss 0.09257442504167557\n",
      "74 0.09257442504167557\n",
      "75\n",
      "loss 0.09588310867547989\n",
      "75 0.09588310867547989\n",
      "76\n",
      "loss 0.0918661579489708\n",
      "76 0.0918661579489708\n",
      "77\n",
      "loss 0.09173137694597244\n",
      "77 0.09173137694597244\n",
      "78\n",
      "loss 0.09329067915678024\n",
      "78 0.09329067915678024\n",
      "79\n",
      "loss 0.09691020101308823\n",
      "79 0.09691020101308823\n",
      "80\n",
      "loss 0.09239692240953445\n",
      "80 0.09239692240953445\n",
      "81\n",
      "loss 0.09640754759311676\n",
      "81 0.09640754759311676\n",
      "82\n",
      "loss 0.09299523383378983\n",
      "82 0.09299523383378983\n",
      "83\n",
      "loss 0.08991744369268417\n",
      "83 0.08991744369268417\n",
      "84\n",
      "loss 0.08911905437707901\n",
      "84 0.08911905437707901\n",
      "85\n",
      "loss 0.09386810660362244\n",
      "85 0.09386810660362244\n",
      "86\n",
      "loss 0.09155888110399246\n",
      "86 0.09155888110399246\n",
      "87\n",
      "loss 0.08808715641498566\n",
      "87 0.08808715641498566\n",
      "88\n",
      "loss 0.08980610966682434\n",
      "88 0.08980610966682434\n",
      "89\n",
      "loss 0.08675823360681534\n",
      "89 0.08675823360681534\n",
      "90\n",
      "loss 0.09113702178001404\n",
      "90 0.09113702178001404\n",
      "91\n",
      "loss 0.08932436257600784\n",
      "91 0.08932436257600784\n",
      "92\n",
      "loss 0.09095785021781921\n",
      "92 0.09095785021781921\n",
      "93\n",
      "loss 0.08946911245584488\n",
      "93 0.08946911245584488\n",
      "94\n",
      "loss 0.08891678601503372\n",
      "94 0.08891678601503372\n",
      "95\n",
      "loss 0.08782243728637695\n",
      "95 0.08782243728637695\n",
      "96\n",
      "loss 0.09412256628274918\n",
      "96 0.09412256628274918\n",
      "97\n",
      "loss 0.08729126304388046\n",
      "97 0.08729126304388046\n",
      "98\n",
      "loss 0.09122440218925476\n",
      "98 0.09122440218925476\n",
      "99\n",
      "loss 0.08673182129859924\n",
      "99 0.08673182129859924\n",
      "100\n",
      "loss 0.08991974592208862\n",
      "100 0.08991974592208862\n",
      "101\n",
      "loss 0.08450359106063843\n",
      "101 0.08450359106063843\n",
      "102\n",
      "loss 0.08552291244268417\n",
      "102 0.08552291244268417\n",
      "103\n",
      "loss 0.08390910178422928\n",
      "103 0.08390910178422928\n",
      "104\n",
      "loss 0.08689859509468079\n",
      "104 0.08689859509468079\n",
      "105\n",
      "loss 0.08248535543680191\n",
      "105 0.08248535543680191\n",
      "106\n",
      "loss 0.08258934319019318\n",
      "106 0.08258934319019318\n",
      "107\n",
      "loss 0.08296193927526474\n",
      "107 0.08296193927526474\n",
      "108\n",
      "loss 0.08147795498371124\n",
      "108 0.08147795498371124\n",
      "109\n",
      "loss 0.08855284750461578\n",
      "109 0.08855284750461578\n",
      "110\n",
      "loss 0.08033640682697296\n",
      "110 0.08033640682697296\n",
      "111\n",
      "loss 0.08411765098571777\n",
      "111 0.08411765098571777\n",
      "112\n",
      "loss 0.084218829870224\n",
      "112 0.084218829870224\n",
      "113\n",
      "loss 0.08451543003320694\n",
      "113 0.08451543003320694\n",
      "114\n",
      "loss 0.08848591148853302\n",
      "114 0.08848591148853302\n",
      "115\n",
      "loss 0.08358719944953918\n",
      "115 0.08358719944953918\n",
      "116\n",
      "loss 0.08442212641239166\n",
      "116 0.08442212641239166\n",
      "117\n",
      "loss 0.08680953085422516\n",
      "117 0.08680953085422516\n",
      "118\n",
      "loss 0.08214641362428665\n",
      "118 0.08214641362428665\n",
      "119\n",
      "loss 0.08359707146883011\n",
      "119 0.08359707146883011\n",
      "120\n",
      "loss 0.08684024214744568\n",
      "120 0.08684024214744568\n",
      "121\n",
      "loss 0.08107390999794006\n",
      "121 0.08107390999794006\n",
      "122\n",
      "loss 0.08216118067502975\n",
      "122 0.08216118067502975\n",
      "123\n",
      "loss 0.08393446356058121\n",
      "123 0.08393446356058121\n",
      "124\n",
      "loss 0.07959756255149841\n",
      "124 0.07959756255149841\n",
      "125\n",
      "loss 0.080843485891819\n",
      "125 0.080843485891819\n",
      "126\n",
      "loss 0.08869417011737823\n",
      "126 0.08869417011737823\n",
      "127\n",
      "loss 0.08977783471345901\n",
      "127 0.08977783471345901\n",
      "128\n",
      "loss 0.0813499465584755\n",
      "128 0.0813499465584755\n",
      "129\n",
      "loss 0.0799526646733284\n",
      "129 0.0799526646733284\n",
      "130\n",
      "loss 0.08073488622903824\n",
      "130 0.08073488622903824\n",
      "131\n",
      "loss 0.08887384086847305\n",
      "131 0.08887384086847305\n",
      "132\n",
      "loss 0.08571255207061768\n",
      "132 0.08571255207061768\n",
      "133\n",
      "loss 0.07898672670125961\n",
      "133 0.07898672670125961\n",
      "134\n",
      "loss 0.07894258201122284\n",
      "134 0.07894258201122284\n",
      "135\n",
      "loss 0.0803586095571518\n",
      "135 0.0803586095571518\n",
      "136\n",
      "loss 0.08424993604421616\n",
      "136 0.08424993604421616\n",
      "137\n",
      "loss 0.08386266976594925\n",
      "137 0.08386266976594925\n",
      "138\n",
      "loss 0.08226333558559418\n",
      "138 0.08226333558559418\n",
      "139\n",
      "loss 0.0765681117773056\n",
      "139 0.0765681117773056\n",
      "140\n",
      "loss 0.07569514214992523\n",
      "140 0.07569514214992523\n",
      "141\n",
      "loss 0.0829363763332367\n",
      "141 0.0829363763332367\n",
      "142\n",
      "loss 0.08316987752914429\n",
      "142 0.08316987752914429\n",
      "143\n",
      "loss 0.08028576523065567\n",
      "143 0.08028576523065567\n",
      "144\n",
      "loss 0.08397521823644638\n",
      "144 0.08397521823644638\n",
      "145\n",
      "loss 0.07890162616968155\n",
      "145 0.07890162616968155\n",
      "146\n",
      "loss 0.07899836450815201\n",
      "146 0.07899836450815201\n",
      "147\n",
      "loss 0.07991946488618851\n",
      "147 0.07991946488618851\n",
      "148\n",
      "loss 0.08162108808755875\n",
      "148 0.08162108808755875\n",
      "149\n",
      "loss 0.07928860187530518\n",
      "149 0.07928860187530518\n",
      "150\n",
      "loss 0.08397629112005234\n",
      "150 0.08397629112005234\n",
      "151\n",
      "loss 0.08178979903459549\n",
      "151 0.08178979903459549\n",
      "152\n",
      "loss 0.08054862171411514\n",
      "152 0.08054862171411514\n",
      "153\n",
      "loss 0.07752452790737152\n",
      "153 0.07752452790737152\n",
      "154\n",
      "loss 0.07809527963399887\n",
      "154 0.07809527963399887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "loss 0.08308904618024826\n",
      "155 0.08308904618024826\n",
      "156\n",
      "loss 0.08173616230487823\n",
      "156 0.08173616230487823\n",
      "157\n",
      "loss 0.08922941982746124\n",
      "157 0.08922941982746124\n",
      "158\n",
      "loss 0.07504663616418839\n",
      "158 0.07504663616418839\n",
      "159\n",
      "loss 0.07734651118516922\n",
      "159 0.07734651118516922\n",
      "160\n",
      "loss 0.08114420622587204\n",
      "160 0.08114420622587204\n",
      "161\n",
      "loss 0.0781087577342987\n",
      "161 0.0781087577342987\n",
      "162\n",
      "loss 0.07478395849466324\n",
      "162 0.07478395849466324\n",
      "163\n",
      "loss 0.07423744350671768\n",
      "163 0.07423744350671768\n",
      "164\n",
      "loss 0.0788407027721405\n",
      "164 0.0788407027721405\n",
      "165\n",
      "loss 0.08124508708715439\n",
      "165 0.08124508708715439\n",
      "166\n",
      "loss 0.07724631577730179\n",
      "166 0.07724631577730179\n",
      "167\n",
      "loss 0.0765928402543068\n",
      "167 0.0765928402543068\n",
      "168\n",
      "loss 0.07926450669765472\n",
      "168 0.07926450669765472\n",
      "169\n",
      "loss 0.08260143548250198\n",
      "169 0.08260143548250198\n",
      "170\n",
      "loss 0.07869573682546616\n",
      "170 0.07869573682546616\n",
      "171\n",
      "loss 0.07328296452760696\n",
      "171 0.07328296452760696\n",
      "172\n",
      "loss 0.08077511936426163\n",
      "172 0.08077511936426163\n",
      "173\n",
      "loss 0.07781713455915451\n",
      "173 0.07781713455915451\n",
      "174\n",
      "loss 0.07381937652826309\n",
      "174 0.07381937652826309\n",
      "175\n",
      "loss 0.07589300721883774\n",
      "175 0.07589300721883774\n",
      "176\n",
      "loss 0.07447214424610138\n",
      "176 0.07447214424610138\n",
      "177\n",
      "loss 0.07602103799581528\n",
      "177 0.07602103799581528\n",
      "178\n",
      "loss 0.08160602301359177\n",
      "178 0.08160602301359177\n",
      "179\n",
      "loss 0.07755523920059204\n",
      "179 0.07755523920059204\n",
      "180\n",
      "loss 0.07562629878520966\n",
      "180 0.07562629878520966\n",
      "181\n",
      "loss 0.08013074100017548\n",
      "181 0.08013074100017548\n",
      "182\n",
      "loss 0.07997593283653259\n",
      "182 0.07997593283653259\n",
      "183\n",
      "loss 0.07825279235839844\n",
      "183 0.07825279235839844\n",
      "184\n",
      "loss 0.08110911399126053\n",
      "184 0.08110911399126053\n",
      "185\n",
      "loss 0.07977908849716187\n",
      "185 0.07977908849716187\n",
      "186\n",
      "loss 0.07814810425043106\n",
      "186 0.07814810425043106\n",
      "187\n",
      "loss 0.07317008823156357\n",
      "187 0.07317008823156357\n",
      "188\n",
      "loss 0.07388743758201599\n",
      "188 0.07388743758201599\n",
      "189\n",
      "loss 0.07874017208814621\n",
      "189 0.07874017208814621\n",
      "190\n",
      "loss 0.07380544394254684\n",
      "190 0.07380544394254684\n",
      "191\n",
      "loss 0.07700367271900177\n",
      "191 0.07700367271900177\n",
      "192\n",
      "loss 0.07921326905488968\n",
      "192 0.07921326905488968\n",
      "193\n",
      "loss 0.0730203315615654\n",
      "193 0.0730203315615654\n",
      "194\n",
      "loss 0.07877250760793686\n",
      "194 0.07877250760793686\n",
      "195\n",
      "loss 0.07273861020803452\n",
      "195 0.07273861020803452\n",
      "196\n",
      "loss 0.07151845842599869\n",
      "196 0.07151845842599869\n",
      "197\n",
      "loss 0.07889943569898605\n",
      "197 0.07889943569898605\n",
      "198\n",
      "loss 0.07048370689153671\n",
      "198 0.07048370689153671\n",
      "199\n",
      "loss 0.07722759991884232\n",
      "199 0.07722759991884232\n",
      "200\n",
      "loss 0.07511842250823975\n",
      "200 0.07511842250823975\n",
      "201\n",
      "loss 0.07190213352441788\n",
      "201 0.07190213352441788\n",
      "202\n",
      "loss 0.0793008953332901\n",
      "202 0.0793008953332901\n",
      "203\n",
      "loss 0.07489219307899475\n",
      "203 0.07489219307899475\n",
      "204\n",
      "loss 0.07737953960895538\n",
      "204 0.07737953960895538\n",
      "205\n",
      "loss 0.06848753988742828\n",
      "205 0.06848753988742828\n",
      "206\n",
      "loss 0.07082167267799377\n",
      "206 0.07082167267799377\n",
      "207\n",
      "loss 0.06763031333684921\n",
      "207 0.06763031333684921\n",
      "208\n",
      "loss 0.07221180200576782\n",
      "208 0.07221180200576782\n",
      "209\n",
      "loss 0.0694829598069191\n",
      "209 0.0694829598069191\n",
      "210\n",
      "loss 0.0688854455947876\n",
      "210 0.0688854455947876\n",
      "211\n",
      "loss 0.07197047770023346\n",
      "211 0.07197047770023346\n",
      "212\n",
      "loss 0.0757206380367279\n",
      "212 0.0757206380367279\n",
      "213\n",
      "loss 0.07642191648483276\n",
      "213 0.07642191648483276\n",
      "214\n",
      "loss 0.07066166400909424\n",
      "214 0.07066166400909424\n",
      "215\n",
      "loss 0.06936496496200562\n",
      "215 0.06936496496200562\n",
      "216\n",
      "loss 0.06917072087526321\n",
      "216 0.06917072087526321\n",
      "217\n",
      "loss 0.07522772252559662\n",
      "217 0.07522772252559662\n",
      "218\n",
      "loss 0.07145757973194122\n",
      "218 0.07145757973194122\n",
      "219\n",
      "loss 0.07490968704223633\n",
      "219 0.07490968704223633\n",
      "220\n",
      "loss 0.07484143227338791\n",
      "220 0.07484143227338791\n",
      "221\n",
      "loss 0.07427394390106201\n",
      "221 0.07427394390106201\n",
      "222\n",
      "loss 0.0705568864941597\n",
      "222 0.0705568864941597\n",
      "223\n",
      "loss 0.07047411054372787\n",
      "223 0.07047411054372787\n",
      "224\n",
      "loss 0.07006439566612244\n",
      "224 0.07006439566612244\n",
      "225\n",
      "loss 0.06888552010059357\n",
      "225 0.06888552010059357\n",
      "226\n",
      "loss 0.0672340914607048\n",
      "226 0.0672340914607048\n",
      "227\n",
      "loss 0.07106722146272659\n",
      "227 0.07106722146272659\n",
      "228\n",
      "loss 0.0716949924826622\n",
      "228 0.0716949924826622\n",
      "229\n",
      "loss 0.07078817486763\n",
      "229 0.07078817486763\n",
      "230\n",
      "loss 0.06842423230409622\n",
      "230 0.06842423230409622\n",
      "231\n",
      "loss 0.06634745001792908\n",
      "231 0.06634745001792908\n",
      "232\n",
      "loss 0.06865033507347107\n",
      "232 0.06865033507347107\n",
      "233\n",
      "loss 0.06900756061077118\n",
      "233 0.06900756061077118\n",
      "234\n",
      "loss 0.06927832216024399\n",
      "234 0.06927832216024399\n",
      "235\n",
      "loss 0.06774376332759857\n",
      "235 0.06774376332759857\n",
      "236\n",
      "loss 0.06838688254356384\n",
      "236 0.06838688254356384\n",
      "237\n",
      "loss 0.0705706775188446\n",
      "237 0.0705706775188446\n",
      "238\n",
      "loss 0.06782334297895432\n",
      "238 0.06782334297895432\n",
      "239\n",
      "loss 0.06765858829021454\n",
      "239 0.06765858829021454\n",
      "240\n",
      "loss 0.06807456165552139\n",
      "240 0.06807456165552139\n",
      "241\n",
      "loss 0.06982334703207016\n",
      "241 0.06982334703207016\n",
      "242\n",
      "loss 0.06786514073610306\n",
      "242 0.06786514073610306\n",
      "243\n",
      "loss 0.06911136955022812\n",
      "243 0.06911136955022812\n",
      "244\n",
      "loss 0.06558956205844879\n",
      "244 0.06558956205844879\n",
      "245\n",
      "loss 0.07437295466661453\n",
      "245 0.07437295466661453\n",
      "246\n",
      "loss 0.0711367279291153\n",
      "246 0.0711367279291153\n",
      "247\n",
      "loss 0.06954838335514069\n",
      "247 0.06954838335514069\n",
      "248\n",
      "loss 0.07090142369270325\n",
      "248 0.07090142369270325\n",
      "249\n",
      "loss 0.07168290764093399\n",
      "249 0.07168290764093399\n",
      "250\n",
      "loss 0.07016877084970474\n",
      "250 0.07016877084970474\n",
      "251\n",
      "loss 0.06410939991474152\n",
      "251 0.06410939991474152\n",
      "252\n",
      "loss 0.06761503964662552\n",
      "252 0.06761503964662552\n",
      "253\n",
      "loss 0.06772542744874954\n",
      "253 0.06772542744874954\n",
      "254\n",
      "loss 0.06347119808197021\n",
      "254 0.06347119808197021\n",
      "255\n",
      "loss 0.07162608206272125\n",
      "255 0.07162608206272125\n",
      "256\n",
      "loss 0.060826804488897324\n",
      "256 0.060826804488897324\n",
      "257\n",
      "loss 0.06599272042512894\n",
      "257 0.06599272042512894\n",
      "258\n",
      "loss 0.06984412670135498\n",
      "258 0.06984412670135498\n",
      "259\n",
      "loss 0.07034814357757568\n",
      "259 0.07034814357757568\n",
      "260\n",
      "loss 0.06693315505981445\n",
      "260 0.06693315505981445\n",
      "261\n",
      "loss 0.07242855429649353\n",
      "261 0.07242855429649353\n",
      "262\n",
      "loss 0.07257644087076187\n",
      "262 0.07257644087076187\n",
      "263\n",
      "loss 0.06423932313919067\n",
      "263 0.06423932313919067\n",
      "264\n",
      "loss 0.06645672023296356\n",
      "264 0.06645672023296356\n",
      "265\n",
      "loss 0.07016139477491379\n",
      "265 0.07016139477491379\n",
      "266\n",
      "loss 0.06788262724876404\n",
      "266 0.06788262724876404\n",
      "267\n",
      "loss 0.0683368667960167\n",
      "267 0.0683368667960167\n",
      "268\n",
      "loss 0.0644761472940445\n",
      "268 0.0644761472940445\n",
      "269\n",
      "loss 0.06300859153270721\n",
      "269 0.06300859153270721\n",
      "270\n",
      "loss 0.06885506212711334\n",
      "270 0.06885506212711334\n",
      "271\n",
      "loss 0.061903245747089386\n",
      "271 0.061903245747089386\n",
      "272\n",
      "loss 0.06765012443065643\n",
      "272 0.06765012443065643\n",
      "273\n",
      "loss 0.06662507355213165\n",
      "273 0.06662507355213165\n",
      "274\n",
      "loss 0.07185930013656616\n",
      "274 0.07185930013656616\n",
      "275\n",
      "loss 0.06650152802467346\n",
      "275 0.06650152802467346\n",
      "276\n",
      "loss 0.06449336558580399\n",
      "276 0.06449336558580399\n",
      "277\n",
      "loss 0.06402382254600525\n",
      "277 0.06402382254600525\n",
      "278\n",
      "loss 0.06582535803318024\n",
      "278 0.06582535803318024\n",
      "279\n",
      "loss 0.06532355397939682\n",
      "279 0.06532355397939682\n",
      "280\n",
      "loss 0.06645162403583527\n",
      "280 0.06645162403583527\n",
      "281\n",
      "loss 0.06983194500207901\n",
      "281 0.06983194500207901\n",
      "282\n",
      "loss 0.06503372639417648\n",
      "282 0.06503372639417648\n",
      "283\n",
      "loss 0.061676934361457825\n",
      "283 0.061676934361457825\n",
      "284\n",
      "loss 0.06691036373376846\n",
      "284 0.06691036373376846\n",
      "285\n",
      "loss 0.06604842841625214\n",
      "285 0.06604842841625214\n",
      "286\n",
      "loss 0.06358841806650162\n",
      "286 0.06358841806650162\n",
      "287\n",
      "loss 0.0655130073428154\n",
      "287 0.0655130073428154\n",
      "288\n",
      "loss 0.06569904088973999\n",
      "288 0.06569904088973999\n",
      "289\n",
      "loss 0.06529725342988968\n",
      "289 0.06529725342988968\n",
      "290\n",
      "loss 0.06353107839822769\n",
      "290 0.06353107839822769\n",
      "291\n",
      "loss 0.06520497798919678\n",
      "291 0.06520497798919678\n",
      "292\n",
      "loss 0.06651496142148972\n",
      "292 0.06651496142148972\n",
      "293\n",
      "loss 0.05793068930506706\n",
      "293 0.05793068930506706\n",
      "294\n",
      "loss 0.06278260052204132\n",
      "294 0.06278260052204132\n",
      "295\n",
      "loss 0.07137182354927063\n",
      "295 0.07137182354927063\n",
      "296\n",
      "loss 0.0648949071764946\n",
      "296 0.0648949071764946\n",
      "297\n",
      "loss 0.06348501145839691\n",
      "297 0.06348501145839691\n",
      "298\n",
      "loss 0.0631277933716774\n",
      "298 0.0631277933716774\n",
      "299\n",
      "loss 0.06416101008653641\n",
      "299 0.06416101008653641\n",
      "300\n",
      "loss 0.06252198666334152\n",
      "300 0.06252198666334152\n",
      "301\n",
      "loss 0.06657623499631882\n",
      "301 0.06657623499631882\n",
      "302\n",
      "loss 0.06474938988685608\n",
      "302 0.06474938988685608\n",
      "303\n",
      "loss 0.06638865917921066\n",
      "303 0.06638865917921066\n",
      "304\n",
      "loss 0.06677167117595673\n",
      "304 0.06677167117595673\n",
      "305\n",
      "loss 0.06275281310081482\n",
      "305 0.06275281310081482\n",
      "306\n",
      "loss 0.06906775385141373\n",
      "306 0.06906775385141373\n",
      "307\n",
      "loss 0.06400652229785919\n",
      "307 0.06400652229785919\n",
      "308\n",
      "loss 0.06014837697148323\n",
      "308 0.06014837697148323\n",
      "309\n",
      "loss 0.06115499138832092\n",
      "309 0.06115499138832092\n",
      "310\n",
      "loss 0.06348799914121628\n",
      "310 0.06348799914121628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n",
      "loss 0.06406255811452866\n",
      "311 0.06406255811452866\n",
      "312\n",
      "loss 0.06568987667560577\n",
      "312 0.06568987667560577\n",
      "313\n",
      "loss 0.06374513357877731\n",
      "313 0.06374513357877731\n",
      "314\n",
      "loss 0.06344214081764221\n",
      "314 0.06344214081764221\n",
      "315\n",
      "loss 0.05657150596380234\n",
      "315 0.05657150596380234\n",
      "316\n",
      "loss 0.06053803116083145\n",
      "316 0.06053803116083145\n",
      "317\n",
      "loss 0.0657505989074707\n",
      "317 0.0657505989074707\n",
      "318\n",
      "loss 0.06096088886260986\n",
      "318 0.06096088886260986\n",
      "319\n",
      "loss 0.06359031051397324\n",
      "319 0.06359031051397324\n",
      "320\n",
      "loss 0.06592909246683121\n",
      "320 0.06592909246683121\n",
      "321\n",
      "loss 0.06396003067493439\n",
      "321 0.06396003067493439\n",
      "322\n",
      "loss 0.05330086499452591\n",
      "322 0.05330086499452591\n",
      "323\n",
      "loss 0.0592854768037796\n",
      "323 0.0592854768037796\n",
      "324\n",
      "loss 0.06062263995409012\n",
      "324 0.06062263995409012\n",
      "325\n",
      "loss 0.06786029040813446\n",
      "325 0.06786029040813446\n",
      "326\n",
      "loss 0.061075419187545776\n",
      "326 0.061075419187545776\n",
      "327\n",
      "loss 0.06012643873691559\n",
      "327 0.06012643873691559\n",
      "328\n",
      "loss 0.06304168701171875\n",
      "328 0.06304168701171875\n",
      "329\n",
      "loss 0.06125587224960327\n",
      "329 0.06125587224960327\n",
      "330\n",
      "loss 0.06483424454927444\n",
      "330 0.06483424454927444\n",
      "331\n",
      "loss 0.056287385523319244\n",
      "331 0.056287385523319244\n",
      "332\n",
      "loss 0.061270371079444885\n",
      "332 0.061270371079444885\n",
      "333\n",
      "loss 0.06276007741689682\n",
      "333 0.06276007741689682\n",
      "334\n",
      "loss 0.06274579465389252\n",
      "334 0.06274579465389252\n",
      "335\n",
      "loss 0.05896185338497162\n",
      "335 0.05896185338497162\n",
      "336\n",
      "loss 0.058752819895744324\n",
      "336 0.058752819895744324\n",
      "337\n",
      "loss 0.06143325939774513\n",
      "337 0.06143325939774513\n",
      "338\n",
      "loss 0.05944042280316353\n",
      "338 0.05944042280316353\n",
      "339\n",
      "loss 0.05568155273795128\n",
      "339 0.05568155273795128\n",
      "340\n",
      "loss 0.0599428154528141\n",
      "340 0.0599428154528141\n",
      "341\n",
      "loss 0.06255781650543213\n",
      "341 0.06255781650543213\n",
      "342\n",
      "loss 0.06054387241601944\n",
      "342 0.06054387241601944\n",
      "343\n",
      "loss 0.061509840190410614\n",
      "343 0.061509840190410614\n",
      "344\n",
      "loss 0.05996571108698845\n",
      "344 0.05996571108698845\n",
      "345\n",
      "loss 0.0609217993915081\n",
      "345 0.0609217993915081\n",
      "346\n",
      "loss 0.06172400712966919\n",
      "346 0.06172400712966919\n",
      "347\n",
      "loss 0.05877363309264183\n",
      "347 0.05877363309264183\n",
      "348\n",
      "loss 0.06562169641256332\n",
      "348 0.06562169641256332\n",
      "349\n",
      "loss 0.05539665371179581\n",
      "349 0.05539665371179581\n",
      "350\n",
      "loss 0.06617199629545212\n",
      "350 0.06617199629545212\n",
      "351\n",
      "loss 0.0569063164293766\n",
      "351 0.0569063164293766\n",
      "352\n",
      "loss 0.06641852855682373\n",
      "352 0.06641852855682373\n",
      "353\n",
      "loss 0.06529513746500015\n",
      "353 0.06529513746500015\n",
      "354\n",
      "loss 0.057953592389822006\n",
      "354 0.057953592389822006\n",
      "355\n",
      "loss 0.0596502386033535\n",
      "355 0.0596502386033535\n",
      "356\n",
      "loss 0.05650857836008072\n",
      "356 0.05650857836008072\n",
      "357\n",
      "loss 0.05943921208381653\n",
      "357 0.05943921208381653\n",
      "358\n",
      "loss 0.05571848526597023\n",
      "358 0.05571848526597023\n",
      "359\n",
      "loss 0.05767827853560448\n",
      "359 0.05767827853560448\n",
      "360\n",
      "loss 0.05656999349594116\n",
      "360 0.05656999349594116\n",
      "361\n",
      "loss 0.05829450860619545\n",
      "361 0.05829450860619545\n",
      "362\n",
      "loss 0.06158171594142914\n",
      "362 0.06158171594142914\n",
      "363\n",
      "loss 0.061460886150598526\n",
      "363 0.061460886150598526\n",
      "364\n",
      "loss 0.054847750812768936\n",
      "364 0.054847750812768936\n",
      "365\n",
      "loss 0.05451533943414688\n",
      "365 0.05451533943414688\n",
      "366\n",
      "loss 0.06044730171561241\n",
      "366 0.06044730171561241\n",
      "367\n",
      "loss 0.05667321756482124\n",
      "367 0.05667321756482124\n",
      "368\n",
      "loss 0.057166822254657745\n",
      "368 0.057166822254657745\n",
      "369\n",
      "loss 0.056703850626945496\n",
      "369 0.056703850626945496\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "isnan = False\n",
    "while True:\n",
    "    if isnan:\n",
    "        break\n",
    "    for batch in train_loader:\n",
    "        targets = torch.Tensor(batch['blend']).transpose(1, 2).to(device)\n",
    "        inputs = get_hubert_feature(batch['wav'])\n",
    "        inputs = F.interpolate(inputs, size=(targets.shape[2]), mode='linear')\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs, targets)\n",
    "        \n",
    "        print(step)\n",
    "        loss = 0\n",
    "        for key in outputs.keys():\n",
    "            if 'loss' in key:\n",
    "                loss += outputs[key]\n",
    "                print(key, outputs[key].item())\n",
    "        if torch.isnan(loss):\n",
    "            isnan = True\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(step, loss.item())\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            writer.add_scalar('train_loss', loss.item(), step)\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            display.clear_output()\n",
    "            \n",
    "            losses = []\n",
    "            for i, batch in enumerate(test_loader):\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                    \n",
    "                targets = torch.Tensor(batch['blend']).transpose(1, 2).to(device)\n",
    "                inputs = get_hubert_feature(batch['wav'])\n",
    "                inputs = F.interpolate(inputs, size=(targets.shape[2]), mode='linear')\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs, targets)\n",
    "                    \n",
    "                loss = 0\n",
    "                for key in outputs.keys():\n",
    "                    if 'loss' in key:\n",
    "                        loss += outputs[key]\n",
    "                print('test :', i, loss.item())\n",
    "                losses.append(loss)        \n",
    "            \n",
    "            test_loss = torch.stack(losses).mean().item()\n",
    "            print('test_loss :', test_loss)\n",
    "            writer.add_scalar('test_loss', test_loss, step)\n",
    "            \n",
    "#             plt.figure(figsize=[18, 4])\n",
    "#             librosa.display.specshow(targets[0].data.cpu().numpy(), cmap='magma')\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.figure(figsize=[18, 4])\n",
    "#             librosa.display.specshow(outputs['y_pred'][0].data.cpu().numpy(), cmap='magma')\n",
    "#             plt.show()\n",
    "            \n",
    "#             for i in [20, 37]:\n",
    "#                 plt.figure(figsize=[18, 2])\n",
    "#                 plt.title(str(i))\n",
    "#                 plt.plot(targets[0].data.cpu().numpy()[i])\n",
    "#                 plt.plot(outputs['y_pred'][0].data.cpu().numpy()[i])\n",
    "#                 plt.show()\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            save(save_dir, step, model, None, optimizer)\n",
    "    \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c85fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1166d67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce39d126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45b0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be174d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
