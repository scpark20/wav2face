{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79d0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6665403e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 20 18:41:13 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| 30%   25C    P8    13W / 230W |   2522MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000    Off  | 00000000:1C:00.0 Off |                  Off |\n",
      "| 30%   26C    P8    17W / 230W |   2866MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A5000    Off  | 00000000:1D:00.0 Off |                  Off |\n",
      "| 30%   26C    P8    15W / 230W |   2496MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A5000    Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 30%   25C    P8    18W / 230W |   3122MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA RTX A5000    Off  | 00000000:89:00.0 Off |                  Off |\n",
      "| 30%   38C    P3    87W / 230W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA RTX A5000    Off  | 00000000:8A:00.0 Off |                  Off |\n",
      "| 30%   26C    P8    21W / 230W |   1320MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA RTX A5000    Off  | 00000000:8B:00.0 Off |                  Off |\n",
      "| 30%   25C    P8    18W / 230W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA RTX A5000    Off  | 00000000:8C:00.0 Off |                  Off |\n",
      "| 30%   25C    P8    16W / 230W |  11090MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A    393011      C   ...onda3/envs/ste/bin/python     1066MiB |\n",
      "|    0   N/A  N/A   1868773      C   ...onda3/envs/ste/bin/python      978MiB |\n",
      "|    0   N/A  N/A   1868774      C   ...onda3/envs/ste/bin/python      470MiB |\n",
      "|    1   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A     10954      C   ...hyun/anaconda3/bin/python     2858MiB |\n",
      "|    2   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A     10640      C   ...hyun/anaconda3/bin/python     2488MiB |\n",
      "|    3   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A    218422      C   ...nda3/envs/byte/bin/python     3114MiB |\n",
      "|    4   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A    245538      C   ...onda3/envs/ste/bin/python     1312MiB |\n",
      "|    6   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A    753221      C   ...3/envs/bytesep/bin/python    11082MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee05e12",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb821737",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 768\n",
    "n_outputs = 61\n",
    "n_frames = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c54e68",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedcf798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from model.model_transformer_reg import Model\n",
    "from utils.util import *\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Model\n",
    "model = Model(in_dim=n_mels, h_dim=512, out_dim=n_outputs)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "188bd5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet.bias\n",
      "encoder.attn_layers.0.emb_rel_k\n",
      "encoder.attn_layers.0.emb_rel_v\n",
      "encoder.attn_layers.0.conv_q.weight\n",
      "encoder.attn_layers.0.conv_q.bias\n",
      "encoder.attn_layers.0.conv_k.weight\n",
      "encoder.attn_layers.0.conv_k.bias\n",
      "encoder.attn_layers.0.conv_v.weight\n",
      "encoder.attn_layers.0.conv_v.bias\n",
      "encoder.attn_layers.0.conv_o.weight\n",
      "encoder.attn_layers.0.conv_o.bias\n",
      "encoder.attn_layers.1.emb_rel_k\n",
      "encoder.attn_layers.1.emb_rel_v\n",
      "encoder.attn_layers.1.conv_q.weight\n",
      "encoder.attn_layers.1.conv_q.bias\n",
      "encoder.attn_layers.1.conv_k.weight\n",
      "encoder.attn_layers.1.conv_k.bias\n",
      "encoder.attn_layers.1.conv_v.weight\n",
      "encoder.attn_layers.1.conv_v.bias\n",
      "encoder.attn_layers.1.conv_o.weight\n",
      "encoder.attn_layers.1.conv_o.bias\n",
      "encoder.attn_layers.2.emb_rel_k\n",
      "encoder.attn_layers.2.emb_rel_v\n",
      "encoder.attn_layers.2.conv_q.weight\n",
      "encoder.attn_layers.2.conv_q.bias\n",
      "encoder.attn_layers.2.conv_k.weight\n",
      "encoder.attn_layers.2.conv_k.bias\n",
      "encoder.attn_layers.2.conv_v.weight\n",
      "encoder.attn_layers.2.conv_v.bias\n",
      "encoder.attn_layers.2.conv_o.weight\n",
      "encoder.attn_layers.2.conv_o.bias\n",
      "encoder.attn_layers.3.emb_rel_k\n",
      "encoder.attn_layers.3.emb_rel_v\n",
      "encoder.attn_layers.3.conv_q.weight\n",
      "encoder.attn_layers.3.conv_q.bias\n",
      "encoder.attn_layers.3.conv_k.weight\n",
      "encoder.attn_layers.3.conv_k.bias\n",
      "encoder.attn_layers.3.conv_v.weight\n",
      "encoder.attn_layers.3.conv_v.bias\n",
      "encoder.attn_layers.3.conv_o.weight\n",
      "encoder.attn_layers.3.conv_o.bias\n",
      "encoder.attn_layers.4.emb_rel_k\n",
      "encoder.attn_layers.4.emb_rel_v\n",
      "encoder.attn_layers.4.conv_q.weight\n",
      "encoder.attn_layers.4.conv_q.bias\n",
      "encoder.attn_layers.4.conv_k.weight\n",
      "encoder.attn_layers.4.conv_k.bias\n",
      "encoder.attn_layers.4.conv_v.weight\n",
      "encoder.attn_layers.4.conv_v.bias\n",
      "encoder.attn_layers.4.conv_o.weight\n",
      "encoder.attn_layers.4.conv_o.bias\n",
      "encoder.attn_layers.5.emb_rel_k\n",
      "encoder.attn_layers.5.emb_rel_v\n",
      "encoder.attn_layers.5.conv_q.weight\n",
      "encoder.attn_layers.5.conv_q.bias\n",
      "encoder.attn_layers.5.conv_k.weight\n",
      "encoder.attn_layers.5.conv_k.bias\n",
      "encoder.attn_layers.5.conv_v.weight\n",
      "encoder.attn_layers.5.conv_v.bias\n",
      "encoder.attn_layers.5.conv_o.weight\n",
      "encoder.attn_layers.5.conv_o.bias\n",
      "encoder.norm_layers_1.0.gamma\n",
      "encoder.norm_layers_1.0.beta\n",
      "encoder.norm_layers_1.1.gamma\n",
      "encoder.norm_layers_1.1.beta\n",
      "encoder.norm_layers_1.2.gamma\n",
      "encoder.norm_layers_1.2.beta\n",
      "encoder.norm_layers_1.3.gamma\n",
      "encoder.norm_layers_1.3.beta\n",
      "encoder.norm_layers_1.4.gamma\n",
      "encoder.norm_layers_1.4.beta\n",
      "encoder.norm_layers_1.5.gamma\n",
      "encoder.norm_layers_1.5.beta\n",
      "encoder.ffn_layers.0.conv_1.weight\n",
      "encoder.ffn_layers.0.conv_1.bias\n",
      "encoder.ffn_layers.0.conv_2.weight\n",
      "encoder.ffn_layers.0.conv_2.bias\n",
      "encoder.ffn_layers.1.conv_1.weight\n",
      "encoder.ffn_layers.1.conv_1.bias\n",
      "encoder.ffn_layers.1.conv_2.weight\n",
      "encoder.ffn_layers.1.conv_2.bias\n",
      "encoder.ffn_layers.2.conv_1.weight\n",
      "encoder.ffn_layers.2.conv_1.bias\n",
      "encoder.ffn_layers.2.conv_2.weight\n",
      "encoder.ffn_layers.2.conv_2.bias\n",
      "encoder.ffn_layers.3.conv_1.weight\n",
      "encoder.ffn_layers.3.conv_1.bias\n",
      "encoder.ffn_layers.3.conv_2.weight\n",
      "encoder.ffn_layers.3.conv_2.bias\n",
      "encoder.ffn_layers.4.conv_1.weight\n",
      "encoder.ffn_layers.4.conv_1.bias\n",
      "encoder.ffn_layers.4.conv_2.weight\n",
      "encoder.ffn_layers.4.conv_2.bias\n",
      "encoder.ffn_layers.5.conv_1.weight\n",
      "encoder.ffn_layers.5.conv_1.bias\n",
      "encoder.ffn_layers.5.conv_2.weight\n",
      "encoder.ffn_layers.5.conv_2.bias\n",
      "encoder.norm_layers_2.0.gamma\n",
      "encoder.norm_layers_2.0.beta\n",
      "encoder.norm_layers_2.1.gamma\n",
      "encoder.norm_layers_2.1.beta\n",
      "encoder.norm_layers_2.2.gamma\n",
      "encoder.norm_layers_2.2.beta\n",
      "encoder.norm_layers_2.3.gamma\n",
      "encoder.norm_layers_2.3.beta\n",
      "encoder.norm_layers_2.4.gamma\n",
      "encoder.norm_layers_2.4.beta\n",
      "encoder.norm_layers_2.5.gamma\n",
      "encoder.norm_layers_2.5.beta\n",
      "postnet.weight\n",
      "postnet.bias\n",
      "warm start\n"
     ]
    }
   ],
   "source": [
    "# warm start\n",
    "checkpoint = torch.load('/data/scpark/save/lips/train06.23-1/save_120000', map_location=torch.device('cpu'))\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "for key in checkpoint['model_state_dict']:\n",
    "    if key in model_state_dict.keys():\n",
    "        if checkpoint['model_state_dict'][key].shape == model_state_dict[key].shape:\n",
    "            model_state_dict[key] = checkpoint['model_state_dict'][key]\n",
    "            print(key)\n",
    "model.load_state_dict(model_state_dict, strict=True)\n",
    "print('warm start')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31748b8c",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998d7f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 521832\r\n",
      "-rw-rw-r-- 1 scpark scpark 534355839  7월 20 18:40 save_0\r\n",
      "-rw-rw-r-- 1 scpark scpark         0  7월 20 18:39 events.out.tfevents.1689845967.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark         0  7월 20 18:29 events.out.tfevents.1689845389.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark         0  7월 20 18:27 events.out.tfevents.1689845277.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark         0  7월 20 18:26 events.out.tfevents.1689845180.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark         0  7월 20 18:23 events.out.tfevents.1689845034.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark         0  7월 20 18:14 events.out.tfevents.1689844454.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark         0  7월 20 18:14 events.out.tfevents.1689844452.GPUSVR01\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lips/train07.20-1/'\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model, _, optimizer = load(save_dir, 133000, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d7b3c",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a8aa62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_6_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_7_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_9_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_10_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_6_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_7_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_9_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_10_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_11_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_12_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_9_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_10_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_6_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_7_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_9_iPhone_raw.npy\n",
      "36 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data.arkit_dataset import LipsDataset, CombinedDataset, CombinedCollate\n",
    "\n",
    "root_dir = '/data/speech/digital_human/preprocessed/'\n",
    "files = sorted([os.path.join(root_dir, file) for file in os.listdir(root_dir)])\n",
    "print(len(files))\n",
    "\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    dataset = LipsDataset(file, n_mels, n_frames)\n",
    "    if '_10_' in file:\n",
    "        test_datasets.append(dataset)\n",
    "    else:\n",
    "        train_datasets.append(dataset)\n",
    "print(len(train_datasets), len(test_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc7cac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(CombinedDataset(train_datasets), \n",
    "                                           num_workers=16, shuffle=True, batch_size=32, collate_fn=CombinedCollate())\n",
    "test_loader = torch.utils.data.DataLoader(CombinedDataset(test_datasets), \n",
    "                                          num_workers=10, shuffle=True, batch_size=10, collate_fn=CombinedCollate())\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a68ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 18:41:42 | INFO | fairseq.tasks.hubert_pretraining | current directory is /home/scpark/projects/wav2face\n",
      "2023-07-20 18:41:42 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'metadata', 'fine_tuning': False, 'labels': ['km'], 'label_dir': 'label', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
      "2023-07-20 18:41:42 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import fairseq\n",
    "from torchaudio.transforms import Resample\n",
    "\n",
    "resample = Resample(24000, 16000)\n",
    "\n",
    "ckpt_path = \"/Storage/speech/pretrained/contentvec/checkpoint_best_legacy_500.pt\"\n",
    "hubert, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
    "hubert = hubert[0]\n",
    "hubert = hubert.to(device)\n",
    "hubert.eval()\n",
    "\n",
    "def get_hubert_feature(wav):\n",
    "    with torch.no_grad():\n",
    "        # (b, t, c)\n",
    "        wav = resample(torch.Tensor(wav)).to(device)\n",
    "        feature = hubert.extract_features(wav, output_layer=12)[0]\n",
    "        return feature.transpose(1, 2)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03238ce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test : 0 0.05214358866214752\n",
      "test : 1 0.057785555720329285\n",
      "test : 2 0.05865137651562691\n",
      "test : 3 0.04913139343261719\n",
      "test : 4 0.06084894761443138\n",
      "test : 5 0.05780322849750519\n",
      "test : 6 0.06041058525443077\n",
      "test : 7 0.05593559890985489\n",
      "test : 8 0.05820368975400925\n",
      "test : 9 0.05801958590745926\n",
      "test_loss : 0.05689335614442825\n",
      "saved /data/scpark/save/lips/train07.20-1/save_0\n",
      "1\n",
      "loss 0.05239885300397873\n",
      "1 0.05239885300397873\n",
      "2\n",
      "loss 0.04586300253868103\n",
      "2 0.04586300253868103\n",
      "3\n",
      "loss 0.047861773520708084\n",
      "3 0.047861773520708084\n",
      "4\n",
      "loss 0.051491837948560715\n",
      "4 0.051491837948560715\n",
      "5\n",
      "loss 0.04675668105483055\n",
      "5 0.04675668105483055\n",
      "6\n",
      "loss 0.05098067596554756\n",
      "6 0.05098067596554756\n",
      "7\n",
      "loss 0.052576612681150436\n",
      "7 0.052576612681150436\n",
      "8\n",
      "loss 0.05175600200891495\n",
      "8 0.05175600200891495\n",
      "9\n",
      "loss 0.04775285720825195\n",
      "9 0.04775285720825195\n",
      "10\n",
      "loss 0.04956114664673805\n",
      "10 0.04956114664673805\n",
      "11\n",
      "loss 0.04847735911607742\n",
      "11 0.04847735911607742\n",
      "12\n",
      "loss 0.04936465993523598\n",
      "12 0.04936465993523598\n",
      "13\n",
      "loss 0.045202407985925674\n",
      "13 0.045202407985925674\n",
      "14\n",
      "loss 0.05242764204740524\n",
      "14 0.05242764204740524\n",
      "15\n",
      "loss 0.051724523305892944\n",
      "15 0.051724523305892944\n",
      "16\n",
      "loss 0.050113141536712646\n",
      "16 0.050113141536712646\n",
      "17\n",
      "loss 0.04976624622941017\n",
      "17 0.04976624622941017\n",
      "18\n",
      "loss 0.04833764210343361\n",
      "18 0.04833764210343361\n",
      "19\n",
      "loss 0.04422510787844658\n",
      "19 0.04422510787844658\n",
      "20\n",
      "loss 0.04881587624549866\n",
      "20 0.04881587624549866\n",
      "21\n",
      "loss 0.050247352570295334\n",
      "21 0.050247352570295334\n",
      "22\n",
      "loss 0.04842169210314751\n",
      "22 0.04842169210314751\n",
      "23\n",
      "loss 0.05523006245493889\n",
      "23 0.05523006245493889\n",
      "24\n",
      "loss 0.050140880048274994\n",
      "24 0.050140880048274994\n",
      "25\n",
      "loss 0.048558373004198074\n",
      "25 0.048558373004198074\n",
      "26\n",
      "loss 0.04645135626196861\n",
      "26 0.04645135626196861\n",
      "27\n",
      "loss 0.05248742923140526\n",
      "27 0.05248742923140526\n",
      "28\n",
      "loss 0.04872382432222366\n",
      "28 0.04872382432222366\n",
      "29\n",
      "loss 0.05144859477877617\n",
      "29 0.05144859477877617\n",
      "30\n",
      "loss 0.049927935004234314\n",
      "30 0.049927935004234314\n",
      "31\n",
      "loss 0.04645497724413872\n",
      "31 0.04645497724413872\n",
      "32\n",
      "loss 0.049375031143426895\n",
      "32 0.049375031143426895\n",
      "33\n",
      "loss 0.046730175614356995\n",
      "33 0.046730175614356995\n",
      "34\n",
      "loss 0.04886789619922638\n",
      "34 0.04886789619922638\n",
      "35\n",
      "loss 0.04734819382429123\n",
      "35 0.04734819382429123\n",
      "36\n",
      "loss 0.05307700112462044\n",
      "36 0.05307700112462044\n",
      "37\n",
      "loss 0.04894458130002022\n",
      "37 0.04894458130002022\n",
      "38\n",
      "loss 0.04747837409377098\n",
      "38 0.04747837409377098\n",
      "39\n",
      "loss 0.04880596324801445\n",
      "39 0.04880596324801445\n",
      "40\n",
      "loss 0.043206386268138885\n",
      "40 0.043206386268138885\n",
      "41\n",
      "loss 0.04627932608127594\n",
      "41 0.04627932608127594\n",
      "42\n",
      "loss 0.0533466637134552\n",
      "42 0.0533466637134552\n",
      "43\n",
      "loss 0.04898272082209587\n",
      "43 0.04898272082209587\n",
      "44\n",
      "loss 0.050987359136343\n",
      "44 0.050987359136343\n",
      "45\n",
      "loss 0.044927529990673065\n",
      "45 0.044927529990673065\n",
      "46\n",
      "loss 0.044420480728149414\n",
      "46 0.044420480728149414\n",
      "47\n",
      "loss 0.048675715923309326\n",
      "47 0.048675715923309326\n",
      "48\n",
      "loss 0.048678867518901825\n",
      "48 0.048678867518901825\n",
      "49\n",
      "loss 0.0465751476585865\n",
      "49 0.0465751476585865\n",
      "50\n",
      "loss 0.04464440420269966\n",
      "50 0.04464440420269966\n",
      "51\n",
      "loss 0.046380311250686646\n",
      "51 0.046380311250686646\n",
      "52\n",
      "loss 0.04711194708943367\n",
      "52 0.04711194708943367\n",
      "53\n",
      "loss 0.046701692044734955\n",
      "53 0.046701692044734955\n",
      "54\n",
      "loss 0.04739106819033623\n",
      "54 0.04739106819033623\n",
      "55\n",
      "loss 0.04386821389198303\n",
      "55 0.04386821389198303\n",
      "56\n",
      "loss 0.04786715656518936\n",
      "56 0.04786715656518936\n",
      "57\n",
      "loss 0.04276437684893608\n",
      "57 0.04276437684893608\n",
      "58\n",
      "loss 0.04519830271601677\n",
      "58 0.04519830271601677\n",
      "59\n",
      "loss 0.043305013328790665\n",
      "59 0.043305013328790665\n",
      "60\n",
      "loss 0.047555360943078995\n",
      "60 0.047555360943078995\n",
      "61\n",
      "loss 0.04394509270787239\n",
      "61 0.04394509270787239\n",
      "62\n",
      "loss 0.04889016970992088\n",
      "62 0.04889016970992088\n",
      "63\n",
      "loss 0.042232830077409744\n",
      "63 0.042232830077409744\n",
      "64\n",
      "loss 0.044893428683280945\n",
      "64 0.044893428683280945\n",
      "65\n",
      "loss 0.040260907262563705\n",
      "65 0.040260907262563705\n",
      "66\n",
      "loss 0.04319089651107788\n",
      "66 0.04319089651107788\n",
      "67\n",
      "loss 0.04576583951711655\n",
      "67 0.04576583951711655\n",
      "68\n",
      "loss 0.042343441396951675\n",
      "68 0.042343441396951675\n",
      "69\n",
      "loss 0.0453449971973896\n",
      "69 0.0453449971973896\n",
      "70\n",
      "loss 0.03813953697681427\n",
      "70 0.03813953697681427\n",
      "71\n",
      "loss 0.036388099193573\n",
      "71 0.036388099193573\n",
      "72\n",
      "loss 0.042633216828107834\n",
      "72 0.042633216828107834\n",
      "73\n",
      "loss 0.03779766336083412\n",
      "73 0.03779766336083412\n",
      "74\n",
      "loss 0.04449440538883209\n",
      "74 0.04449440538883209\n",
      "75\n",
      "loss 0.04562853276729584\n",
      "75 0.04562853276729584\n",
      "76\n",
      "loss 0.04263003543019295\n",
      "76 0.04263003543019295\n",
      "77\n",
      "loss 0.041362788528203964\n",
      "77 0.041362788528203964\n",
      "78\n",
      "loss 0.04449334368109703\n",
      "78 0.04449334368109703\n",
      "79\n",
      "loss 0.04128430038690567\n",
      "79 0.04128430038690567\n",
      "80\n",
      "loss 0.041295114904642105\n",
      "80 0.041295114904642105\n",
      "81\n",
      "loss 0.038400474935770035\n",
      "81 0.038400474935770035\n",
      "82\n",
      "loss 0.042011942714452744\n",
      "82 0.042011942714452744\n",
      "83\n",
      "loss 0.04870579019188881\n",
      "83 0.04870579019188881\n",
      "84\n",
      "loss 0.0423220731317997\n",
      "84 0.0423220731317997\n",
      "85\n",
      "loss 0.042944274842739105\n",
      "85 0.042944274842739105\n",
      "86\n",
      "loss 0.04499956965446472\n",
      "86 0.04499956965446472\n",
      "87\n",
      "loss 0.03870319947600365\n",
      "87 0.03870319947600365\n",
      "88\n",
      "loss 0.041488517075777054\n",
      "88 0.041488517075777054\n",
      "89\n",
      "loss 0.045964743942022324\n",
      "89 0.045964743942022324\n",
      "90\n",
      "loss 0.04196341708302498\n",
      "90 0.04196341708302498\n",
      "91\n",
      "loss 0.04488145187497139\n",
      "91 0.04488145187497139\n",
      "92\n",
      "loss 0.043873466551303864\n",
      "92 0.043873466551303864\n",
      "93\n",
      "loss 0.03877957537770271\n",
      "93 0.03877957537770271\n",
      "94\n",
      "loss 0.041373636573553085\n",
      "94 0.041373636573553085\n",
      "95\n",
      "loss 0.04442237317562103\n",
      "95 0.04442237317562103\n",
      "96\n",
      "loss 0.03727886825799942\n",
      "96 0.03727886825799942\n",
      "97\n",
      "loss 0.04327462986111641\n",
      "97 0.04327462986111641\n",
      "98\n",
      "loss 0.040931157767772675\n",
      "98 0.040931157767772675\n",
      "99\n",
      "loss 0.04535021632909775\n",
      "99 0.04535021632909775\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "isnan = False\n",
    "while True:\n",
    "    if isnan:\n",
    "        break\n",
    "    for batch in train_loader:\n",
    "        targets = torch.Tensor(batch['blend']).transpose(1, 2).to(device)\n",
    "        inputs = get_hubert_feature(batch['wav'])\n",
    "        inputs = F.interpolate(inputs, size=(targets.shape[2]), mode='linear')\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs, targets)\n",
    "        \n",
    "        print(step)\n",
    "        loss = 0\n",
    "        for key in outputs.keys():\n",
    "            if 'loss' in key:\n",
    "                loss += outputs[key]\n",
    "                print(key, outputs[key].item())\n",
    "        if torch.isnan(loss):\n",
    "            isnan = True\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(step, loss.item())\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            writer.add_scalar('train_loss', loss.item(), step)\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            display.clear_output()\n",
    "            \n",
    "            losses = []\n",
    "            for i, batch in enumerate(test_loader):\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                    \n",
    "                targets = torch.Tensor(batch['blend']).transpose(1, 2).to(device)\n",
    "                inputs = get_hubert_feature(batch['wav'])\n",
    "                inputs = F.interpolate(inputs, size=(targets.shape[2]), mode='linear')\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs, targets)\n",
    "                    \n",
    "                loss = 0\n",
    "                for key in outputs.keys():\n",
    "                    if 'loss' in key:\n",
    "                        loss += outputs[key]\n",
    "                print('test :', i, loss.item())\n",
    "                losses.append(loss)        \n",
    "            \n",
    "            test_loss = torch.stack(losses).mean().item()\n",
    "            print('test_loss :', test_loss)\n",
    "            writer.add_scalar('test_loss', test_loss, step)\n",
    "            \n",
    "#             plt.figure(figsize=[18, 4])\n",
    "#             librosa.display.specshow(targets[0].data.cpu().numpy(), cmap='magma')\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.figure(figsize=[18, 4])\n",
    "#             librosa.display.specshow(outputs['y_pred'][0].data.cpu().numpy(), cmap='magma')\n",
    "#             plt.show()\n",
    "            \n",
    "#             for i in [20, 37]:\n",
    "#                 plt.figure(figsize=[18, 2])\n",
    "#                 plt.title(str(i))\n",
    "#                 plt.plot(targets[0].data.cpu().numpy()[i])\n",
    "#                 plt.plot(outputs['y_pred'][0].data.cpu().numpy()[i])\n",
    "#                 plt.show()\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            save(save_dir, step, model, None, optimizer)\n",
    "    \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c85fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1166d67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce39d126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760151ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
