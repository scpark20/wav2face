{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79d0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6665403e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 30 02:32:46 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| 30%   28C    P8    13W / 230W |    475MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000    Off  | 00000000:1C:00.0 Off |                  Off |\n",
      "| 30%   28C    P8    16W / 230W |   5476MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A5000    Off  | 00000000:1D:00.0 Off |                  Off |\n",
      "| 30%   42C    P2    59W / 230W |   8687MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A5000    Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 31%   54C    P2    72W / 230W |    577MiB / 24564MiB |     46%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA RTX A5000    Off  | 00000000:89:00.0 Off |                  Off |\n",
      "| 30%   44C    P8    18W / 230W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA RTX A5000    Off  | 00000000:8A:00.0 Off |                  Off |\n",
      "| 30%   39C    P2    61W / 230W |    505MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA RTX A5000    Off  | 00000000:8B:00.0 Off |                  Off |\n",
      "| 30%   28C    P8    18W / 230W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA RTX A5000    Off  | 00000000:8C:00.0 Off |                  Off |\n",
      "| 30%   27C    P8    17W / 230W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A   3105924      C   ...onda3/envs/ste/bin/python      467MiB |\n",
      "|    1   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A   2665624      C   ...hyun/anaconda3/bin/python     2653MiB |\n",
      "|    1   N/A  N/A   2668046      C   ...hyun/anaconda3/bin/python     2815MiB |\n",
      "|    2   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A   2807525      C   ...onda3/envs/ste/bin/python     8679MiB |\n",
      "|    3   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A   2561159      C   ByteSep Inference                 569MiB |\n",
      "|    4   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A   3240180      C   ...onda3/envs/ste/bin/python      497MiB |\n",
      "|    6   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A      3840      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee05e12",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb821737",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 16\n",
    "n_outputs = 61\n",
    "n_frames = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c54e68",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedcf798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from model.model_transformer_vae import Model\n",
    "from utils.util import *\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Model\n",
    "model = Model(in_dim=n_mels, h_dim=512, out_dim=n_outputs, z_dim=2)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31748b8c",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998d7f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 582876\r\n",
      "-rw-rw-r-- 1 scpark scpark       226  6월 30 02:31 events.out.tfevents.1688059646.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark 596853693  6월 30 02:28 save_0\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lips/train06.30-3/'\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model, _, optimizer = load(save_dir, 56389, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d7b3c",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8aa62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_6_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_7_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_9_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_10_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_6_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_7_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_9_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_10_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_11_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_12_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_9_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_10_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_6_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_7_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_9_iPhone_raw.npy\n",
      "36 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data.arkit_dataset import LipsDataset, CombinedDataset, CombinedCollate\n",
    "\n",
    "root_dir = '/data/speech/digital_human/preprocessed/'\n",
    "files = sorted([os.path.join(root_dir, file) for file in os.listdir(root_dir)])\n",
    "print(len(files))\n",
    "\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    dataset = LipsDataset(file, n_mels, n_frames)\n",
    "    if '_10_' in file:\n",
    "        test_datasets.append(dataset)\n",
    "    else:\n",
    "        train_datasets.append(dataset)\n",
    "print(len(train_datasets), len(test_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc7cac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(CombinedDataset(train_datasets), \n",
    "                                           num_workers=16, shuffle=True, batch_size=32, collate_fn=CombinedCollate())\n",
    "test_loader = torch.utils.data.DataLoader(CombinedDataset(test_datasets), \n",
    "                                          num_workers=10, shuffle=True, batch_size=10, collate_fn=CombinedCollate())\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03238ce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test : 0 0.12470778822898865\n",
      "test : 1 0.12388160079717636\n",
      "test : 2 0.09616456925868988\n",
      "test : 3 0.12147191166877747\n",
      "test : 4 0.08433421701192856\n",
      "test : 5 0.08297432214021683\n",
      "test : 6 0.16215018928050995\n",
      "test : 7 0.09365224838256836\n",
      "test : 8 0.0932600349187851\n",
      "test : 9 0.12279090285301208\n",
      "test_loss : 0.1105387806892395\n",
      "101\n",
      "recon_loss 0.0909586027264595\n",
      "kl_loss 0.04986285790801048\n",
      "102\n",
      "recon_loss 0.091574527323246\n",
      "kl_loss 0.12661969661712646\n",
      "103\n",
      "recon_loss 0.09164980798959732\n",
      "kl_loss 0.10577131807804108\n",
      "104\n",
      "recon_loss 0.09293236583471298\n",
      "kl_loss 0.09790465235710144\n",
      "105\n",
      "recon_loss 0.09281086176633835\n",
      "kl_loss 0.05303310230374336\n",
      "106\n",
      "recon_loss 0.09098462760448456\n",
      "kl_loss 0.07207165658473969\n",
      "107\n",
      "recon_loss 0.09367584437131882\n",
      "kl_loss 0.07575385272502899\n",
      "108\n",
      "recon_loss 0.08994591236114502\n",
      "kl_loss 0.06809104233980179\n",
      "109\n",
      "recon_loss 0.09341570734977722\n",
      "kl_loss 0.04804379865527153\n",
      "110\n",
      "recon_loss 0.09311584383249283\n",
      "kl_loss 0.05842270702123642\n",
      "111\n",
      "recon_loss 0.09067795425653458\n",
      "kl_loss 0.060382407158613205\n",
      "112\n",
      "recon_loss 0.09387747198343277\n",
      "kl_loss 0.038649383932352066\n",
      "113\n",
      "recon_loss 0.09311627596616745\n",
      "kl_loss 0.03170264512300491\n",
      "114\n",
      "recon_loss 0.09183979779481888\n",
      "kl_loss 0.05830615013837814\n",
      "115\n",
      "recon_loss 0.08896273374557495\n",
      "kl_loss 0.047736313194036484\n",
      "116\n",
      "recon_loss 0.09040077030658722\n",
      "kl_loss 0.04037940502166748\n",
      "117\n",
      "recon_loss 0.09127285331487656\n",
      "kl_loss 0.0400446318089962\n",
      "118\n",
      "recon_loss 0.09063561260700226\n",
      "kl_loss 0.09332190454006195\n",
      "119\n",
      "recon_loss 0.09020476788282394\n",
      "kl_loss 0.03280925005674362\n",
      "120\n",
      "recon_loss 0.08982064574956894\n",
      "kl_loss 0.04528626427054405\n",
      "121\n",
      "recon_loss 0.08793217688798904\n",
      "kl_loss 0.031178299337625504\n",
      "122\n",
      "recon_loss 0.09047841280698776\n",
      "kl_loss 0.07450918108224869\n",
      "123\n",
      "recon_loss 0.08827052265405655\n",
      "kl_loss 0.03451403230428696\n",
      "124\n",
      "recon_loss 0.08962524682283401\n",
      "kl_loss 0.04985397681593895\n",
      "125\n",
      "recon_loss 0.08784777671098709\n",
      "kl_loss 0.07406295835971832\n",
      "126\n",
      "recon_loss 0.09108642488718033\n",
      "kl_loss 0.03435158729553223\n",
      "127\n",
      "recon_loss 0.08990784734487534\n",
      "kl_loss 0.031554993242025375\n",
      "128\n",
      "recon_loss 0.08659069985151291\n",
      "kl_loss 0.0465037077665329\n",
      "129\n",
      "recon_loss 0.08411078155040741\n",
      "kl_loss 0.04138245806097984\n",
      "130\n",
      "recon_loss 0.08727467060089111\n",
      "kl_loss 0.030068613588809967\n",
      "131\n",
      "recon_loss 0.08985847979784012\n",
      "kl_loss 0.043832436203956604\n",
      "132\n",
      "recon_loss 0.08433006703853607\n",
      "kl_loss 0.039960719645023346\n",
      "133\n",
      "recon_loss 0.08679725229740143\n",
      "kl_loss 0.042458850890398026\n",
      "134\n",
      "recon_loss 0.08611828088760376\n",
      "kl_loss 0.026841595768928528\n",
      "135\n",
      "recon_loss 0.088239885866642\n",
      "kl_loss 0.04877014458179474\n",
      "136\n",
      "recon_loss 0.0826365053653717\n",
      "kl_loss 0.046224966645240784\n",
      "137\n",
      "recon_loss 0.08833534270524979\n",
      "kl_loss 0.04568421468138695\n",
      "138\n",
      "recon_loss 0.08535526692867279\n",
      "kl_loss 0.03413593769073486\n",
      "139\n",
      "recon_loss 0.08409661054611206\n",
      "kl_loss 0.033871106803417206\n",
      "140\n",
      "recon_loss 0.08398772776126862\n",
      "kl_loss 0.033074233680963516\n",
      "141\n",
      "recon_loss 0.08805318921804428\n",
      "kl_loss 0.04628501087427139\n",
      "142\n",
      "recon_loss 0.08558349311351776\n",
      "kl_loss 0.053140584379434586\n",
      "143\n",
      "recon_loss 0.0857335701584816\n",
      "kl_loss 0.026041164994239807\n",
      "144\n",
      "recon_loss 0.08590788394212723\n",
      "kl_loss 0.04121360182762146\n",
      "145\n",
      "recon_loss 0.08675901591777802\n",
      "kl_loss 0.03887929767370224\n",
      "146\n",
      "recon_loss 0.08427810668945312\n",
      "kl_loss 0.02398696169257164\n",
      "147\n",
      "recon_loss 0.08144635707139969\n",
      "kl_loss 0.031493134796619415\n",
      "148\n",
      "recon_loss 0.08540051430463791\n",
      "kl_loss 0.041082702577114105\n",
      "149\n",
      "recon_loss 0.08473874628543854\n",
      "kl_loss 0.026960469782352448\n",
      "150\n",
      "recon_loss 0.0873565599322319\n",
      "kl_loss 0.027113910764455795\n",
      "151\n",
      "recon_loss 0.08779871463775635\n",
      "kl_loss 0.03501071408390999\n",
      "152\n",
      "recon_loss 0.08477677404880524\n",
      "kl_loss 0.028183739632368088\n",
      "153\n",
      "recon_loss 0.08597378432750702\n",
      "kl_loss 0.03690284118056297\n",
      "154\n",
      "recon_loss 0.08563120663166046\n",
      "kl_loss 0.03223033249378204\n",
      "155\n",
      "recon_loss 0.08666770160198212\n",
      "kl_loss 0.041977979242801666\n",
      "156\n",
      "recon_loss 0.08267613500356674\n",
      "kl_loss 0.038250625133514404\n",
      "157\n",
      "recon_loss 0.084056556224823\n",
      "kl_loss 0.02717699110507965\n",
      "158\n",
      "recon_loss 0.08582502603530884\n",
      "kl_loss 0.025671595707535744\n",
      "159\n",
      "recon_loss 0.08404786139726639\n",
      "kl_loss 0.05620555207133293\n",
      "160\n",
      "recon_loss 0.08550678938627243\n",
      "kl_loss 0.04272552207112312\n",
      "161\n",
      "recon_loss 0.083323173224926\n",
      "kl_loss 0.026324298232793808\n",
      "162\n",
      "recon_loss 0.08402761071920395\n",
      "kl_loss 0.04463823139667511\n",
      "163\n",
      "recon_loss 0.08193082362413406\n",
      "kl_loss 0.04342743009328842\n",
      "164\n",
      "recon_loss 0.08125245571136475\n",
      "kl_loss 0.040497004985809326\n",
      "165\n",
      "recon_loss 0.08147837966680527\n",
      "kl_loss 0.04679357260465622\n",
      "166\n",
      "recon_loss 0.07970777899026871\n",
      "kl_loss 0.045453257858753204\n",
      "167\n",
      "recon_loss 0.080887570977211\n",
      "kl_loss 0.05308648943901062\n",
      "168\n",
      "recon_loss 0.08114373683929443\n",
      "kl_loss 0.04896707832813263\n",
      "169\n",
      "recon_loss 0.07938885688781738\n",
      "kl_loss 0.04606562852859497\n",
      "170\n",
      "recon_loss 0.08058234304189682\n",
      "kl_loss 0.037262093275785446\n",
      "171\n",
      "recon_loss 0.08112449944019318\n",
      "kl_loss 0.04456496983766556\n",
      "172\n",
      "recon_loss 0.08221516758203506\n",
      "kl_loss 0.043557509779930115\n",
      "173\n",
      "recon_loss 0.08218679577112198\n",
      "kl_loss 0.04279976338148117\n",
      "174\n",
      "recon_loss 0.08060047775506973\n",
      "kl_loss 0.043237075209617615\n",
      "175\n",
      "recon_loss 0.07942292839288712\n",
      "kl_loss 0.041524726897478104\n",
      "176\n",
      "recon_loss 0.07960184663534164\n",
      "kl_loss 0.03052876889705658\n",
      "177\n",
      "recon_loss 0.08040844649076462\n",
      "kl_loss 0.04472111165523529\n",
      "178\n",
      "recon_loss 0.07760612666606903\n",
      "kl_loss 0.04905349388718605\n",
      "179\n",
      "recon_loss 0.08162844926118851\n",
      "kl_loss 0.05904463678598404\n",
      "180\n",
      "recon_loss 0.07850629836320877\n",
      "kl_loss 0.03463982790708542\n",
      "181\n",
      "recon_loss 0.07779284566640854\n",
      "kl_loss 0.04074772074818611\n",
      "182\n",
      "recon_loss 0.07880117744207382\n",
      "kl_loss 0.055003851652145386\n",
      "183\n",
      "recon_loss 0.07993672043085098\n",
      "kl_loss 0.044948600232601166\n",
      "184\n",
      "recon_loss 0.08184859156608582\n",
      "kl_loss 0.06551115959882736\n",
      "185\n",
      "recon_loss 0.07737062126398087\n",
      "kl_loss 0.06711423397064209\n",
      "186\n",
      "recon_loss 0.07913149148225784\n",
      "kl_loss 0.06462783366441727\n",
      "187\n",
      "recon_loss 0.07994166761636734\n",
      "kl_loss 0.0805693119764328\n",
      "188\n",
      "recon_loss 0.07676325738430023\n",
      "kl_loss 0.07338319718837738\n",
      "189\n",
      "recon_loss 0.0781482458114624\n",
      "kl_loss 0.07238943874835968\n",
      "190\n",
      "recon_loss 0.07718139886856079\n",
      "kl_loss 0.07097110152244568\n",
      "191\n",
      "recon_loss 0.07832532376050949\n",
      "kl_loss 0.06412553042173386\n",
      "192\n",
      "recon_loss 0.0776568055152893\n",
      "kl_loss 0.058136098086833954\n",
      "193\n",
      "recon_loss 0.07531219720840454\n",
      "kl_loss 0.07508599758148193\n",
      "194\n",
      "recon_loss 0.07491577416658401\n",
      "kl_loss 0.06522578001022339\n",
      "195\n",
      "recon_loss 0.0786537230014801\n",
      "kl_loss 0.08336018770933151\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "isnan = False\n",
    "while True:\n",
    "    if isnan:\n",
    "        break\n",
    "    for batch in train_loader:\n",
    "        inputs = torch.Tensor(batch['mel']).transpose(1, 2).to(device)\n",
    "        targets = torch.Tensor(batch['blend']).transpose(1, 2).to(device)\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs, targets)\n",
    "        \n",
    "        print(step)\n",
    "        loss = 0\n",
    "        for key in outputs.keys():\n",
    "            if 'kl_loss' in key:\n",
    "                loss += outputs[key] * 1e-2\n",
    "                print(key, outputs[key].item())\n",
    "            elif 'loss' in key:\n",
    "                loss += outputs[key]\n",
    "                print(key, outputs[key].item())\n",
    "        if torch.isnan(loss):\n",
    "            isnan = True\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            writer.add_scalar('train_recon_loss', outputs['recon_loss'].item(), step)\n",
    "            writer.add_scalar('train_kl_loss', outputs['kl_loss'].item(), step)\n",
    "            \n",
    "        if step % 100 == 0:\n",
    "            display.clear_output()\n",
    "            \n",
    "            losses = []\n",
    "            for i, batch in enumerate(test_loader):\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                    \n",
    "                inputs = torch.Tensor(batch['mel']).transpose(1, 2).to(device)\n",
    "                targets = torch.Tensor(batch['blend']).transpose(1, 2).to(device)\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs, targets)\n",
    "                    \n",
    "                loss = 0\n",
    "                for key in outputs.keys():\n",
    "                    if 'loss' in key:\n",
    "                        loss += outputs[key]\n",
    "                print('test :', i, loss.item())\n",
    "                losses.append(loss)        \n",
    "            \n",
    "            test_loss = torch.stack(losses).mean().item()\n",
    "            print('test_loss :', test_loss)\n",
    "            writer.add_scalar('test_loss', test_loss, step)\n",
    "            \n",
    "        if step % 1000 == 0:\n",
    "            save(save_dir, step, model, None, optimizer)\n",
    "    \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c85fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff9705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
