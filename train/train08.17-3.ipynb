{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79d0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6665403e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 17 17:31:07 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.199.02   Driver Version: 470.199.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    64W / 300W |   8777MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  Off  | 00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   49C    P0    71W / 300W |   9123MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  Off  | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   56C    P0   306W / 300W |  61807MiB / 80994MiB |     30%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  Off  | 00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    71W / 300W |   9115MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100 80G...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   56C    P0   268W / 300W |  15949MiB / 80994MiB |     69%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100 80G...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    42W / 300W |     38MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100 80G...  Off  | 00000000:8B:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    40W / 300W |     38MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100 80G...  Off  | 00000000:8C:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    45W / 300W |     38MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    0   N/A  N/A   1581181      C   ...a3/envs/scpark/bin/python     3063MiB |\n",
      "|    0   N/A  N/A   1818556      C   ...envs/scpark/bin/python3.9     1117MiB |\n",
      "|    0   N/A  N/A   1818886      C   ...envs/scpark/bin/python3.9     1885MiB |\n",
      "|    0   N/A  N/A   1819270      C   ...envs/scpark/bin/python3.9     1495MiB |\n",
      "|    0   N/A  N/A   1819827      C   ...envs/scpark/bin/python3.9     1177MiB |\n",
      "|    1   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    1   N/A  N/A   2869198      C   ...a3/envs/scpark/bin/python     9085MiB |\n",
      "|    2   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    2   N/A  N/A    328438      C   ...a3/envs/scpark/bin/python    61769MiB |\n",
      "|    3   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    3   N/A  N/A   4004386      C   ...a3/envs/scpark/bin/python     9077MiB |\n",
      "|    4   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    4   N/A  N/A    802152      C   ...a3/envs/scpark/bin/python    15911MiB |\n",
      "|    5   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    6   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    7   N/A  N/A      2479      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee05e12",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb821737",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 80\n",
    "n_outputs = 61\n",
    "n_frames = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c54e68",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cedcf798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from model.model_conditional_transformer_reg import Model\n",
    "from utils.util import *\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Model\n",
    "model = Model(in_dim=n_mels, h_dim=512, out_dim=n_outputs, n_layers=12)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31748b8c",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "998d7f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lips/train08.17-3/'\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model, _, optimizer = load(save_dir, 130000, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d7b3c",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a8aa62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "1 /data/speech/digital_human/preprocessed/jeewonPark/MH_ARKit_003_10_iPhone_raw.npy\n",
      "1 /data/speech/digital_human/preprocessed/jeewonPark/MH_ARKit_003_11_iPhone_raw.npy\n",
      "1 /data/speech/digital_human/preprocessed/jeewonPark/MH_ARKit_003_12_iPhone_raw.npy\n",
      "1 /data/speech/digital_human/preprocessed/jeewonPark/MH_ARKit_003_1_iPhone_raw.npy\n",
      "1 /data/speech/digital_human/preprocessed/jeewonPark/MH_ARKit_003_2_iPhone_raw.npy\n",
      "1 /data/speech/digital_human/preprocessed/jeewonPark/MH_ARKit_003_3_iPhone_raw.npy\n",
      "1 /data/speech/digital_human/preprocessed/jeewonPark/MH_ARKit_003_4_iPhone_raw.npy\n",
      "1 /data/speech/digital_human/preprocessed/jeewonPark/MH_ARKit_003_5_iPhone_raw.npy\n",
      "1 /data/speech/digital_human/preprocessed/jeewonPark/MH_ARKit_003_8_iPhone_raw.npy\n",
      "1 /data/speech/digital_human/preprocessed/jeewonPark/MH_ARKit_003_9_iPhone_raw.npy\n",
      "2 /data/speech/digital_human/preprocessed/jinwooOh/MH_ARKit_005_10_iPhone_raw.npy\n",
      "2 /data/speech/digital_human/preprocessed/jinwooOh/MH_ARKit_005_1_iPhone_raw.npy\n",
      "2 /data/speech/digital_human/preprocessed/jinwooOh/MH_ARKit_005_2_iPhone_raw.npy\n",
      "2 /data/speech/digital_human/preprocessed/jinwooOh/MH_ARKit_005_3_iPhone_raw.npy\n",
      "2 /data/speech/digital_human/preprocessed/jinwooOh/MH_ARKit_005_4_iPhone_raw.npy\n",
      "2 /data/speech/digital_human/preprocessed/jinwooOh/MH_ARKit_005_5_iPhone_raw.npy\n",
      "2 /data/speech/digital_human/preprocessed/jinwooOh/MH_ARKit_005_6_iPhone_raw.npy\n",
      "2 /data/speech/digital_human/preprocessed/jinwooOh/MH_ARKit_005_7_iPhone_raw.npy\n",
      "2 /data/speech/digital_human/preprocessed/jinwooOh/MH_ARKit_005_8_iPhone_raw.npy\n",
      "2 /data/speech/digital_human/preprocessed/jinwooOh/MH_ARKit_005_9_iPhone_raw.npy\n",
      "3 /data/speech/digital_human/preprocessed/kyuchulLee/MH_ARKit_006_10_iPhone_raw.npy\n",
      "3 /data/speech/digital_human/preprocessed/kyuchulLee/MH_ARKit_006_1_iPhone_raw.npy\n",
      "3 /data/speech/digital_human/preprocessed/kyuchulLee/MH_ARKit_006_2_iPhone_raw.npy\n",
      "3 /data/speech/digital_human/preprocessed/kyuchulLee/MH_ARKit_006_3_iPhone_raw.npy\n",
      "3 /data/speech/digital_human/preprocessed/kyuchulLee/MH_ARKit_006_4_iPhone_raw.npy\n",
      "3 /data/speech/digital_human/preprocessed/kyuchulLee/MH_ARKit_006_5_iPhone_raw.npy\n",
      "3 /data/speech/digital_human/preprocessed/kyuchulLee/MH_ARKit_006_6_iPhone_raw.npy\n",
      "3 /data/speech/digital_human/preprocessed/kyuchulLee/MH_ARKit_006_7_iPhone_raw.npy\n",
      "3 /data/speech/digital_human/preprocessed/kyuchulLee/MH_ARKit_006_8_iPhone_raw.npy\n",
      "3 /data/speech/digital_human/preprocessed/kyuchulLee/MH_ARKit_006_9_iPhone_raw.npy\n",
      "4 /data/speech/digital_human/preprocessed/kyuseokKim/MH_ARKit_002_10_iPhone_raw.npy\n",
      "4 /data/speech/digital_human/preprocessed/kyuseokKim/MH_ARKit_002_1_iPhone_raw.npy\n",
      "4 /data/speech/digital_human/preprocessed/kyuseokKim/MH_ARKit_002_2_iPhone_raw.npy\n",
      "4 /data/speech/digital_human/preprocessed/kyuseokKim/MH_ARKit_002_3_iPhone_raw.npy\n",
      "4 /data/speech/digital_human/preprocessed/kyuseokKim/MH_ARKit_002_4_iPhone_raw.npy\n",
      "4 /data/speech/digital_human/preprocessed/kyuseokKim/MH_ARKit_002_5_iPhone_raw.npy\n",
      "4 /data/speech/digital_human/preprocessed/kyuseokKim/MH_ARKit_002_6_iPhone_raw.npy\n",
      "4 /data/speech/digital_human/preprocessed/kyuseokKim/MH_ARKit_002_7_iPhone_raw.npy\n",
      "4 /data/speech/digital_human/preprocessed/kyuseokKim/MH_ARKit_002_8_iPhone_raw.npy\n",
      "4 /data/speech/digital_human/preprocessed/kyuseokKim/MH_ARKit_002_9_iPhone_raw.npy\n",
      "5 /data/speech/digital_human/preprocessed/nohsikPark/MH_ARKit_010_0_iPhone_raw.npy\n",
      "5 /data/speech/digital_human/preprocessed/nohsikPark/MH_ARKit_010_1_iPhone_raw.npy\n",
      "5 /data/speech/digital_human/preprocessed/nohsikPark/MH_ARKit_010_2_iPhone_raw.npy\n",
      "5 /data/speech/digital_human/preprocessed/nohsikPark/MH_ARKit_010_3_iPhone_raw.npy\n",
      "5 /data/speech/digital_human/preprocessed/nohsikPark/MH_ARKit_010_4_iPhone_raw.npy\n",
      "5 /data/speech/digital_human/preprocessed/nohsikPark/MH_ARKit_010_5_iPhone_raw.npy\n",
      "5 /data/speech/digital_human/preprocessed/nohsikPark/MH_ARKit_010_6_iPhone_raw.npy\n",
      "5 /data/speech/digital_human/preprocessed/nohsikPark/MH_ARKit_010_7_iPhone_raw.npy\n",
      "5 /data/speech/digital_human/preprocessed/nohsikPark/MH_ARKit_010_8_iPhone_raw.npy\n",
      "6 /data/speech/digital_human/preprocessed/soochulPark/MH_ARKit_004_10_iPhone_raw.npy\n",
      "6 /data/speech/digital_human/preprocessed/soochulPark/MH_ARKit_004_1_iPhone_raw.npy\n",
      "6 /data/speech/digital_human/preprocessed/soochulPark/MH_ARKit_004_2_iPhone_raw.npy\n",
      "6 /data/speech/digital_human/preprocessed/soochulPark/MH_ARKit_004_3_iPhone_raw.npy\n",
      "6 /data/speech/digital_human/preprocessed/soochulPark/MH_ARKit_004_4_iPhone_raw.npy\n",
      "6 /data/speech/digital_human/preprocessed/soochulPark/MH_ARKit_004_5_iPhone_raw.npy\n",
      "6 /data/speech/digital_human/preprocessed/soochulPark/MH_ARKit_004_6_iPhone_raw.npy\n",
      "6 /data/speech/digital_human/preprocessed/soochulPark/MH_ARKit_004_7_iPhone_raw.npy\n",
      "6 /data/speech/digital_human/preprocessed/soochulPark/MH_ARKit_004_8_iPhone_raw.npy\n",
      "6 /data/speech/digital_human/preprocessed/soochulPark/MH_ARKit_004_9_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_1_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_20_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_21_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_2_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_30_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_31_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_3_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_40_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_4_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_50_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_51_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_52_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_5_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_6_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_7_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_8_iPhone_raw.npy\n",
      "7 /data/speech/digital_human/preprocessed/yehunHwang/MH_ARKit_001_9_iPhone_raw.npy\n",
      "71 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data.arkit_dataset import LipsDataset, CombinedDataset, CombinedCollate\n",
    "\n",
    "root_dir = '/data/speech/digital_human/preprocessed/'\n",
    "\n",
    "def get_files(dir):\n",
    "    data = []\n",
    "    files = sorted([os.path.join(dir, file) for file in os.listdir(dir)])\n",
    "    for file in files:\n",
    "        if file.endswith('.npy') and 'ARKit' in file:\n",
    "            data.append(file)\n",
    "        if os.path.isdir(file):\n",
    "            data.extend(get_files(os.path.join(dir, file)))\n",
    "    return data\n",
    "\n",
    "files = get_files(root_dir)\n",
    "print(len(files))\n",
    "\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "def get_sid(file):\n",
    "    names = ['No Speaker', 'jeewonPark', 'jinwooOh', 'kyuchulLee', 'kyuseokKim', 'nohsikPark', 'soochulPark', 'yehunHwang']\n",
    "    for sid, name in enumerate(names):\n",
    "        if name in file:\n",
    "            return sid\n",
    "    return 0\n",
    "\n",
    "for file in files:\n",
    "    sid = get_sid(file)\n",
    "    print(sid, file)\n",
    "    dataset = LipsDataset(file, n_mels, n_frames, sid=sid, mel=False)\n",
    "    if '_10_' in file:\n",
    "        test_datasets.append(dataset)\n",
    "    else:\n",
    "        train_datasets.append(dataset)\n",
    "print(len(train_datasets), len(test_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bc7cac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(CombinedDataset(train_datasets), \n",
    "                                           num_workers=16, shuffle=True, batch_size=32, collate_fn=CombinedCollate())\n",
    "test_loader = torch.utils.data.DataLoader(CombinedDataset(test_datasets), \n",
    "                                          num_workers=10, shuffle=True, batch_size=10, collate_fn=CombinedCollate())\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a05691c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from data.audio import mel_spectrogram\n",
    "get_mel = partial(mel_spectrogram, n_fft=2048, num_mels=80, sampling_rate=24000, hop_size=800, win_size=2048, fmin=0, fmax=None, center=False, return_spec=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03238ce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test : 0 0.8174706101417542\n",
      "test : 1 0.8130669593811035\n",
      "test : 2 0.8250216245651245\n",
      "test : 3 0.8283030986785889\n",
      "test : 4 0.8346998691558838\n",
      "test : 5 0.81646728515625\n",
      "test : 6 0.8203819990158081\n",
      "test : 7 0.8358504176139832\n",
      "test : 8 0.824921190738678\n",
      "test : 9 0.8292793035507202\n",
      "test_loss : 0.8245462775230408\n",
      "saved /data/scpark/save/lips/train08.17-3/save_0\n",
      "1\n",
      "loss 0.8055784106254578\n",
      "1 0.8055784106254578\n",
      "2\n",
      "loss 0.5172017216682434\n",
      "2 0.5172017216682434\n",
      "3\n",
      "loss 0.2859923839569092\n",
      "3 0.2859923839569092\n",
      "4\n",
      "loss 0.2090706080198288\n",
      "4 0.2090706080198288\n",
      "5\n",
      "loss 0.19509397447109222\n",
      "5 0.19509397447109222\n",
      "6\n",
      "loss 0.18081140518188477\n",
      "6 0.18081140518188477\n",
      "7\n",
      "loss 0.15973809361457825\n",
      "7 0.15973809361457825\n",
      "8\n",
      "loss 0.15079784393310547\n",
      "8 0.15079784393310547\n",
      "9\n",
      "loss 0.14687177538871765\n",
      "9 0.14687177538871765\n",
      "10\n",
      "loss 0.14022445678710938\n",
      "10 0.14022445678710938\n",
      "11\n",
      "loss 0.13590581715106964\n",
      "11 0.13590581715106964\n",
      "12\n",
      "loss 0.13119246065616608\n",
      "12 0.13119246065616608\n",
      "13\n",
      "loss 0.13265082240104675\n",
      "13 0.13265082240104675\n",
      "14\n",
      "loss 0.1290963739156723\n",
      "14 0.1290963739156723\n",
      "15\n",
      "loss 0.12385489791631699\n",
      "15 0.12385489791631699\n",
      "16\n",
      "loss 0.12545360624790192\n",
      "16 0.12545360624790192\n",
      "17\n",
      "loss 0.12037617713212967\n",
      "17 0.12037617713212967\n",
      "18\n",
      "loss 0.12426988035440445\n",
      "18 0.12426988035440445\n",
      "19\n",
      "loss 0.1188027486205101\n",
      "19 0.1188027486205101\n",
      "20\n",
      "loss 0.11899168789386749\n",
      "20 0.11899168789386749\n",
      "21\n",
      "loss 0.1211215928196907\n",
      "21 0.1211215928196907\n",
      "22\n",
      "loss 0.1163564920425415\n",
      "22 0.1163564920425415\n",
      "23\n",
      "loss 0.11363852769136429\n",
      "23 0.11363852769136429\n",
      "24\n",
      "loss 0.11751660704612732\n",
      "24 0.11751660704612732\n",
      "25\n",
      "loss 0.11551013588905334\n",
      "25 0.11551013588905334\n",
      "26\n",
      "loss 0.112602598965168\n",
      "26 0.112602598965168\n",
      "27\n",
      "loss 0.11572204530239105\n",
      "27 0.11572204530239105\n",
      "28\n",
      "loss 0.11141829937696457\n",
      "28 0.11141829937696457\n",
      "29\n",
      "loss 0.11356818675994873\n",
      "29 0.11356818675994873\n",
      "30\n",
      "loss 0.11120811849832535\n",
      "30 0.11120811849832535\n",
      "31\n",
      "loss 0.1108303815126419\n",
      "31 0.1108303815126419\n",
      "32\n",
      "loss 0.11129941046237946\n",
      "32 0.11129941046237946\n",
      "33\n",
      "loss 0.11168219894170761\n",
      "33 0.11168219894170761\n",
      "34\n",
      "loss 0.10915487259626389\n",
      "34 0.10915487259626389\n",
      "35\n",
      "loss 0.10686173290014267\n",
      "35 0.10686173290014267\n",
      "36\n",
      "loss 0.1079041138291359\n",
      "36 0.1079041138291359\n",
      "37\n",
      "loss 0.10716770589351654\n",
      "37 0.10716770589351654\n",
      "38\n",
      "loss 0.10693487524986267\n",
      "38 0.10693487524986267\n",
      "39\n",
      "loss 0.10817194730043411\n",
      "39 0.10817194730043411\n",
      "40\n",
      "loss 0.10641269385814667\n",
      "40 0.10641269385814667\n",
      "41\n",
      "loss 0.10810026526451111\n",
      "41 0.10810026526451111\n",
      "42\n",
      "loss 0.10451121628284454\n",
      "42 0.10451121628284454\n",
      "43\n",
      "loss 0.10772596299648285\n",
      "43 0.10772596299648285\n",
      "44\n",
      "loss 0.10345904529094696\n",
      "44 0.10345904529094696\n",
      "45\n",
      "loss 0.10355328768491745\n",
      "45 0.10355328768491745\n",
      "46\n",
      "loss 0.1092800423502922\n",
      "46 0.1092800423502922\n",
      "47\n",
      "loss 0.10274308919906616\n",
      "47 0.10274308919906616\n",
      "48\n",
      "loss 0.10561898350715637\n",
      "48 0.10561898350715637\n",
      "49\n",
      "loss 0.10261809080839157\n",
      "49 0.10261809080839157\n",
      "50\n",
      "loss 0.10401829332113266\n",
      "50 0.10401829332113266\n",
      "51\n",
      "loss 0.10152554512023926\n",
      "51 0.10152554512023926\n",
      "52\n",
      "loss 0.0967027097940445\n",
      "52 0.0967027097940445\n",
      "53\n",
      "loss 0.10802154242992401\n",
      "53 0.10802154242992401\n",
      "54\n",
      "loss 0.10008252412080765\n",
      "54 0.10008252412080765\n",
      "55\n",
      "loss 0.10029105842113495\n",
      "55 0.10029105842113495\n",
      "56\n",
      "loss 0.10124910622835159\n",
      "56 0.10124910622835159\n",
      "57\n",
      "loss 0.10238367319107056\n",
      "57 0.10238367319107056\n",
      "58\n",
      "loss 0.10160170495510101\n",
      "58 0.10160170495510101\n",
      "59\n",
      "loss 0.10361478477716446\n",
      "59 0.10361478477716446\n",
      "60\n",
      "loss 0.10096223652362823\n",
      "60 0.10096223652362823\n",
      "61\n",
      "loss 0.10347671061754227\n",
      "61 0.10347671061754227\n",
      "62\n",
      "loss 0.09702108055353165\n",
      "62 0.09702108055353165\n",
      "63\n",
      "loss 0.09738478064537048\n",
      "63 0.09738478064537048\n",
      "64\n",
      "loss 0.09775698930025101\n",
      "64 0.09775698930025101\n",
      "65\n",
      "loss 0.10014215856790543\n",
      "65 0.10014215856790543\n",
      "66\n",
      "loss 0.098176971077919\n",
      "66 0.098176971077919\n",
      "67\n",
      "loss 0.10280967503786087\n",
      "67 0.10280967503786087\n",
      "68\n",
      "loss 0.09924688935279846\n",
      "68 0.09924688935279846\n",
      "69\n",
      "loss 0.09576687961816788\n",
      "69 0.09576687961816788\n",
      "70\n",
      "loss 0.10098690539598465\n",
      "70 0.10098690539598465\n",
      "71\n",
      "loss 0.10175786912441254\n",
      "71 0.10175786912441254\n",
      "72\n",
      "loss 0.09367622435092926\n",
      "72 0.09367622435092926\n",
      "73\n",
      "loss 0.09781067818403244\n",
      "73 0.09781067818403244\n",
      "74\n",
      "loss 0.09624131768941879\n",
      "74 0.09624131768941879\n",
      "75\n",
      "loss 0.09676561504602432\n",
      "75 0.09676561504602432\n",
      "76\n",
      "loss 0.09547305107116699\n",
      "76 0.09547305107116699\n",
      "77\n",
      "loss 0.09371864050626755\n",
      "77 0.09371864050626755\n",
      "78\n",
      "loss 0.10107644647359848\n",
      "78 0.10107644647359848\n",
      "79\n",
      "loss 0.09811535477638245\n",
      "79 0.09811535477638245\n",
      "80\n",
      "loss 0.09674251079559326\n",
      "80 0.09674251079559326\n",
      "81\n",
      "loss 0.09302603453397751\n",
      "81 0.09302603453397751\n",
      "82\n",
      "loss 0.09767361730337143\n",
      "82 0.09767361730337143\n",
      "83\n",
      "loss 0.0999651625752449\n",
      "83 0.0999651625752449\n",
      "84\n",
      "loss 0.09988265484571457\n",
      "84 0.09988265484571457\n",
      "85\n",
      "loss 0.09387965500354767\n",
      "85 0.09387965500354767\n",
      "86\n",
      "loss 0.09539394825696945\n",
      "86 0.09539394825696945\n",
      "87\n",
      "loss 0.09317068755626678\n",
      "87 0.09317068755626678\n",
      "88\n",
      "loss 0.09539258480072021\n",
      "88 0.09539258480072021\n",
      "89\n",
      "loss 0.09558198601007462\n",
      "89 0.09558198601007462\n",
      "90\n",
      "loss 0.09592676162719727\n",
      "90 0.09592676162719727\n",
      "91\n",
      "loss 0.08991986513137817\n",
      "91 0.08991986513137817\n",
      "92\n",
      "loss 0.08949586004018784\n",
      "92 0.08949586004018784\n",
      "93\n",
      "loss 0.09652208536863327\n",
      "93 0.09652208536863327\n",
      "94\n",
      "loss 0.09546046704053879\n",
      "94 0.09546046704053879\n",
      "95\n",
      "loss 0.0952143669128418\n",
      "95 0.0952143669128418\n",
      "96\n",
      "loss 0.09539126604795456\n",
      "96 0.09539126604795456\n",
      "97\n",
      "loss 0.09508015960454941\n",
      "97 0.09508015960454941\n",
      "98\n",
      "loss 0.09779657423496246\n",
      "98 0.09779657423496246\n",
      "99\n",
      "loss 0.08959630876779556\n",
      "99 0.08959630876779556\n",
      "100\n",
      "loss 0.09116702526807785\n",
      "100 0.09116702526807785\n",
      "101\n",
      "loss 0.09978345781564713\n",
      "101 0.09978345781564713\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "isnan = False\n",
    "while True:\n",
    "    if isnan:\n",
    "        break\n",
    "    for batch in train_loader:\n",
    "        inputs = get_mel(torch.Tensor(batch['wav'])).to(device)\n",
    "        targets = torch.Tensor(batch['blend']).transpose(1, 2).to(device)\n",
    "        sid = torch.Tensor(batch['sid']).int().to(device)\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs, targets, sid)\n",
    "        \n",
    "        print(step)\n",
    "        loss = 0\n",
    "        for key in outputs.keys():\n",
    "            if 'loss' in key:\n",
    "                loss += outputs[key]\n",
    "                print(key, outputs[key].item())\n",
    "        if torch.isnan(loss):\n",
    "            isnan = True\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(step, loss.item())\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            writer.add_scalar('train_loss', loss.item(), step)\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            display.clear_output()\n",
    "            \n",
    "            losses = []\n",
    "            for i, batch in enumerate(test_loader):\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                    \n",
    "                inputs = get_mel(torch.Tensor(batch['wav'])).to(device)\n",
    "                targets = torch.Tensor(batch['blend']).transpose(1, 2).to(device)\n",
    "                sid = torch.Tensor(batch['sid']).int().to(device)\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs, targets, sid)\n",
    "                    \n",
    "                loss = 0\n",
    "                for key in outputs.keys():\n",
    "                    if 'loss' in key:\n",
    "                        loss += outputs[key]\n",
    "                print('test :', i, loss.item())\n",
    "                losses.append(loss)        \n",
    "            \n",
    "            test_loss = torch.stack(losses).mean().item()\n",
    "            print('test_loss :', test_loss)\n",
    "            writer.add_scalar('test_loss', test_loss, step)\n",
    "            \n",
    "#             plt.figure(figsize=[18, 4])\n",
    "#             librosa.display.specshow(targets[0].data.cpu().numpy(), cmap='magma')\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.figure(figsize=[18, 4])\n",
    "#             librosa.display.specshow(outputs['y_pred'][0].data.cpu().numpy(), cmap='magma')\n",
    "#             plt.show()\n",
    "            \n",
    "#             for i in [20, 37]:\n",
    "#                 plt.figure(figsize=[18, 2])\n",
    "#                 plt.title(str(i))\n",
    "#                 plt.plot(targets[0].data.cpu().numpy()[i])\n",
    "#                 plt.plot(outputs['y_pred'][0].data.cpu().numpy()[i])\n",
    "#                 plt.show()\n",
    "\n",
    "        if step % 10000 == 0:\n",
    "            save(save_dir, step, model, None, optimizer)\n",
    "    \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c85fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35939c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08695381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2467159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
