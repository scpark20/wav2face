{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79d0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6665403e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 19 17:37:50 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| 30%   27C    P8    14W / 230W |   1433MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000    Off  | 00000000:1C:00.0 Off |                  Off |\n",
      "| 30%   53C    P2   123W / 230W |  20131MiB / 24564MiB |     10%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A5000    Off  | 00000000:1D:00.0 Off |                  Off |\n",
      "| 30%   50C    P2   111W / 230W |  15005MiB / 24564MiB |     69%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A5000    Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 30%   51C    P2   114W / 230W |  16397MiB / 24564MiB |     21%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA RTX A5000    Off  | 00000000:89:00.0 Off |                  Off |\n",
      "| 30%   57C    P2   143W / 230W |  20161MiB / 24564MiB |     15%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA RTX A5000    Off  | 00000000:8A:00.0 Off |                  Off |\n",
      "| 30%   54C    P2   126W / 230W |  16159MiB / 24564MiB |     19%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA RTX A5000    Off  | 00000000:8B:00.0 Off |                  Off |\n",
      "| 30%   28C    P8    17W / 230W |      5MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA RTX A5000    Off  | 00000000:8C:00.0 Off |                  Off |\n",
      "| 30%   38C    P5    63W / 230W |      5MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A   3439958      C   ...3/envs/vspeech/bin/python     1425MiB |\n",
      "|    1   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A   1792411      C   ...3/envs/vspeech/bin/python    20123MiB |\n",
      "|    2   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A   1985994      C   ...3/envs/vspeech/bin/python    14997MiB |\n",
      "|    3   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A   4160782      C   ...3/envs/vspeech/bin/python    16389MiB |\n",
      "|    4   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A    172531      C   ...3/envs/vspeech/bin/python    20153MiB |\n",
      "|    5   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A    299985      C   ...3/envs/vspeech/bin/python    16151MiB |\n",
      "|    6   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A      3580      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee05e12",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb821737",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 8\n",
    "n_outputs = 61\n",
    "n_frames = 400\n",
    "sr = 24000\n",
    "fps = 30\n",
    "train_csv_files = ['/Storage/speech/face/rvh_visme_1_iPhone_30fps.csv',\n",
    "                  '/Storage/speech/face/rvh_visme_2_iPhone_30fps.csv',\n",
    "                  '/Storage/speech/face/rvh_visme_3_iPhone_30fps.csv']\n",
    "train_wav_files = ['/Storage/speech/face/rvh_visme_1_iPhone.wav',\n",
    "                 '/Storage/speech/face/rvh_visme_2_iPhone.wav',\n",
    "                 '/Storage/speech/face/rvh_visme_3_iPhone.wav']\n",
    "\n",
    "test_csv_files = ['/Storage/speech/face/rvh_visme_4_iPhone_30fps.csv']\n",
    "test_wav_files = ['/Storage/speech/face/rvh_visme_4_iPhone.wav']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c54e68",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedcf798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from model.model_vqvae import Model\n",
    "from utils.util import *\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Model\n",
    "model = Model(in_dim=n_mels, out_dim=n_outputs, K=32, latent_dim=256)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31748b8c",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998d7f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1437460\n",
      "-rw-rw-r-- 1 scpark scpark      2312  5월 19 17:37 events.out.tfevents.1684481370.GPUSVR01\n",
      "-rw-rw-r-- 1 scpark scpark 367985211  5월 19 17:37 save_2207\n",
      "-rw-rw-r-- 1 scpark scpark 367985211  5월 19 17:31 save_2000\n",
      "-rw-rw-r-- 1 scpark scpark 367985211  5월 19 17:01 save_1000\n",
      "-rw-rw-r-- 1 scpark scpark 367985211  5월 19 16:30 save_0\n",
      "loaded /data/scpark/save/lips/train05.19-2/save_2207\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lips/train05.19-2/'\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if True:\n",
    "    step, model, _, optimizer = load(save_dir, 2207, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8aa62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset : 22042\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f76dc305b20>\n",
      "test dataset : 7725\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f74976d1520>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from data.dataset import LipsDataset, Collate\n",
    "\n",
    "dataset = LipsDataset(train_wav_files, train_csv_files, n_frames, n_mels=n_mels, sr=sr, fps=fps, perturb=True)\n",
    "print('train dataset :', len(dataset))\n",
    "train_loader = torch.utils.data.DataLoader(dataset, num_workers=1, shuffle=True, batch_size=8, \n",
    "                                           collate_fn=Collate(n_frames, n_mels))\n",
    "print(train_loader)\n",
    "\n",
    "dataset = LipsDataset(test_wav_files, test_csv_files, n_frames, n_mels=n_mels, sr=sr, fps=fps, perturb=False)\n",
    "print('test dataset :', len(dataset))\n",
    "test_loader = torch.utils.data.DataLoader(dataset, num_workers=1, shuffle=True, batch_size=8,\n",
    "                                           collate_fn=Collate(n_frames, n_mels))\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03238ce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test : 0 1.6289610862731934\n",
      "test : 1 1.7040263414382935\n",
      "test : 2 1.6853026151657104\n",
      "test : 3 1.7774617671966553\n",
      "test : 4 1.6469522714614868\n",
      "test : 5 1.660341501235962\n",
      "test : 6 1.6426146030426025\n",
      "test : 7 1.6568784713745117\n",
      "test : 8 1.7601505517959595\n",
      "test : 9 1.7479532957077026\n",
      "test_loss : 1.6910642385482788\n",
      "2601\n",
      "auto_encoding_loss 0.008899270556867123\n",
      "commit_loss 0.003728284267708659\n",
      "zi_prediction_loss 1.1228963136672974\n",
      "2601 1.1355239152908325\n",
      "2602\n",
      "auto_encoding_loss 0.008677895180881023\n",
      "commit_loss 0.003942756447941065\n",
      "zi_prediction_loss 1.0882807970046997\n",
      "2602 1.100901484489441\n",
      "2603\n",
      "auto_encoding_loss 0.008933142758905888\n",
      "commit_loss 0.003887179773300886\n",
      "zi_prediction_loss 1.123780369758606\n",
      "2603 1.1366007328033447\n",
      "2604\n",
      "auto_encoding_loss 0.009739565663039684\n",
      "commit_loss 0.00402429886162281\n",
      "zi_prediction_loss 1.0580904483795166\n",
      "2604 1.0718543529510498\n",
      "2605\n",
      "auto_encoding_loss 0.009941771626472473\n",
      "commit_loss 0.003835946787148714\n",
      "zi_prediction_loss 1.138396143913269\n",
      "2605 1.1521738767623901\n",
      "2606\n",
      "auto_encoding_loss 0.00964761059731245\n",
      "commit_loss 0.0036973878741264343\n",
      "zi_prediction_loss 1.1432890892028809\n",
      "2606 1.1566340923309326\n",
      "2607\n",
      "auto_encoding_loss 0.008157971315085888\n",
      "commit_loss 0.003561538876965642\n",
      "zi_prediction_loss 1.0766726732254028\n",
      "2607 1.0883921384811401\n",
      "2608\n",
      "auto_encoding_loss 0.00850643590092659\n",
      "commit_loss 0.0035137725062668324\n",
      "zi_prediction_loss 1.1096975803375244\n",
      "2608 1.1217178106307983\n",
      "2609\n",
      "auto_encoding_loss 0.008137201890349388\n",
      "commit_loss 0.003928999416530132\n",
      "zi_prediction_loss 1.1072498559951782\n",
      "2609 1.1193161010742188\n",
      "2610\n",
      "auto_encoding_loss 0.008625832386314869\n",
      "commit_loss 0.003554608440026641\n",
      "zi_prediction_loss 1.1226774454116821\n",
      "2610 1.1348578929901123\n",
      "2611\n",
      "auto_encoding_loss 0.010565318167209625\n",
      "commit_loss 0.003813251154497266\n",
      "zi_prediction_loss 1.1419631242752075\n",
      "2611 1.1563416719436646\n",
      "2612\n",
      "auto_encoding_loss 0.009275194257497787\n",
      "commit_loss 0.0037761591374874115\n",
      "zi_prediction_loss 1.1652984619140625\n",
      "2612 1.1783498525619507\n",
      "2613\n",
      "auto_encoding_loss 0.009334171190857887\n",
      "commit_loss 0.00419154716655612\n",
      "zi_prediction_loss 1.042680263519287\n",
      "2613 1.0562059879302979\n",
      "2614\n",
      "auto_encoding_loss 0.009686912409961224\n",
      "commit_loss 0.0038703668396919966\n",
      "zi_prediction_loss 1.150001049041748\n",
      "2614 1.1635583639144897\n",
      "2615\n",
      "auto_encoding_loss 0.009107092395424843\n",
      "commit_loss 0.003931669518351555\n",
      "zi_prediction_loss 1.0425100326538086\n",
      "2615 1.0555487871170044\n",
      "2616\n",
      "auto_encoding_loss 0.009911553002893925\n",
      "commit_loss 0.0044196173548698425\n",
      "zi_prediction_loss 1.0494716167449951\n",
      "2616 1.0638028383255005\n",
      "2617\n",
      "auto_encoding_loss 0.010181339457631111\n",
      "commit_loss 0.004173398949205875\n",
      "zi_prediction_loss 1.002160668373108\n",
      "2617 1.0165153741836548\n",
      "2618\n",
      "auto_encoding_loss 0.00947557482868433\n",
      "commit_loss 0.0036258220206946135\n",
      "zi_prediction_loss 1.0701442956924438\n",
      "2618 1.0832456350326538\n",
      "2619\n",
      "auto_encoding_loss 0.009281064383685589\n",
      "commit_loss 0.003930008038878441\n",
      "zi_prediction_loss 1.077734351158142\n",
      "2619 1.0909454822540283\n",
      "2620\n",
      "auto_encoding_loss 0.010413812473416328\n",
      "commit_loss 0.0035951791796833277\n",
      "zi_prediction_loss 1.1820156574249268\n",
      "2620 1.1960246562957764\n",
      "2621\n",
      "auto_encoding_loss 0.00953521765768528\n",
      "commit_loss 0.004115982446819544\n",
      "zi_prediction_loss 1.0978931188583374\n",
      "2621 1.1115443706512451\n",
      "2622\n",
      "auto_encoding_loss 0.009389198385179043\n",
      "commit_loss 0.004024355206638575\n",
      "zi_prediction_loss 1.0496445894241333\n",
      "2622 1.0630581378936768\n",
      "2623\n",
      "auto_encoding_loss 0.009835198521614075\n",
      "commit_loss 0.0038773815613240004\n",
      "zi_prediction_loss 1.1043418645858765\n",
      "2623 1.1180543899536133\n",
      "2624\n",
      "auto_encoding_loss 0.008152646943926811\n",
      "commit_loss 0.003632246283814311\n",
      "zi_prediction_loss 1.1528961658477783\n",
      "2624 1.164681077003479\n",
      "2625\n",
      "auto_encoding_loss 0.008524193428456783\n",
      "commit_loss 0.0038078634534031153\n",
      "zi_prediction_loss 1.1590462923049927\n",
      "2625 1.1713783740997314\n",
      "2626\n",
      "auto_encoding_loss 0.009383464232087135\n",
      "commit_loss 0.004139291122555733\n",
      "zi_prediction_loss 1.0285018682479858\n",
      "2626 1.0420246124267578\n",
      "2627\n",
      "auto_encoding_loss 0.011520802043378353\n",
      "commit_loss 0.0040900204330682755\n",
      "zi_prediction_loss 1.1973727941513062\n",
      "2627 1.2129836082458496\n",
      "2628\n",
      "auto_encoding_loss 0.009140879847109318\n",
      "commit_loss 0.003996580373495817\n",
      "zi_prediction_loss 1.0928027629852295\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "isnan = False\n",
    "while True:\n",
    "    if isnan:\n",
    "        break\n",
    "    for batch in train_loader:\n",
    "        inputs = batch['inputs'].transpose(1, 2).to(device)\n",
    "        targets = batch['outputs'].transpose(1, 2).to(device)\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs, targets)\n",
    "        \n",
    "        print(step)\n",
    "        loss = 0\n",
    "        for key in outputs.keys():\n",
    "            if 'loss' in key:\n",
    "                loss += outputs[key]\n",
    "                print(key, outputs[key].item())\n",
    "        if torch.isnan(loss):\n",
    "            isnan = True\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(step, loss.item())\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            writer.add_scalar('train_loss', loss.item(), step)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            display.clear_output()\n",
    "            \n",
    "            losses = []\n",
    "            for i, batch in enumerate(test_loader):\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                    \n",
    "                inputs = batch['inputs'].transpose(1, 2).to(device)\n",
    "                targets = batch['outputs'].transpose(1, 2).to(device)\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs, targets)\n",
    "                    \n",
    "                loss = 0\n",
    "                for key in outputs.keys():\n",
    "                    if 'loss' in key:\n",
    "                        loss += outputs[key]\n",
    "                print('test :', i, loss.item())\n",
    "                losses.append(loss)        \n",
    "            \n",
    "            test_loss = torch.stack(losses).mean().item()\n",
    "            print('test_loss :', test_loss)\n",
    "            writer.add_scalar('test_loss', test_loss, step)\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            save(save_dir, step, model, None, optimizer)\n",
    "    \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c85fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6b79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782cfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e8e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste2",
   "language": "python",
   "name": "ste2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
