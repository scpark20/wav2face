{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79d0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6665403e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 12 19:19:14 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| 30%   28C    P8    14W / 230W |   1544MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000    Off  | 00000000:1C:00.0 Off |                  Off |\n",
      "| 30%   27C    P8    14W / 230W |   2866MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A5000    Off  | 00000000:1D:00.0 Off |                  Off |\n",
      "| 30%   27C    P8    16W / 230W |   2496MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A5000    Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 30%   27C    P8    20W / 230W |   3122MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA RTX A5000    Off  | 00000000:89:00.0 Off |                  Off |\n",
      "| 30%   54C    P2    76W / 230W |   6582MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA RTX A5000    Off  | 00000000:8A:00.0 Off |                  Off |\n",
      "| 30%   30C    P8    17W / 230W |   1320MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA RTX A5000    Off  | 00000000:8B:00.0 Off |                  Off |\n",
      "| 30%   58C    P2   212W / 230W |   9410MiB / 24564MiB |     95%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA RTX A5000    Off  | 00000000:8C:00.0 Off |                  Off |\n",
      "| 30%   27C    P8    16W / 230W |   3576MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A    393011      C   ...onda3/envs/ste/bin/python     1066MiB |\n",
      "|    0   N/A  N/A   1564894      C   ...onda3/envs/ste/bin/python      470MiB |\n",
      "|    1   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A     10954      C   ...hyun/anaconda3/bin/python     2858MiB |\n",
      "|    2   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A     10640      C   ...hyun/anaconda3/bin/python     2488MiB |\n",
      "|    3   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A    218422      C   ...nda3/envs/byte/bin/python     3114MiB |\n",
      "|    4   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A   3503197      C   ...onda3/envs/ste/bin/python     6574MiB |\n",
      "|    5   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A    245538      C   ...onda3/envs/ste/bin/python     1312MiB |\n",
      "|    6   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    6   N/A  N/A   2240164      C   ...onda3/envs/ste/bin/python     9402MiB |\n",
      "|    7   N/A  N/A      3569      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A    343993      C   ...3/envs/bytesep/bin/python     3568MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee05e12",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb821737",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 16\n",
    "n_outputs = 61\n",
    "n_frames = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c54e68",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedcf798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from model.model_transformer_reg import Model\n",
    "from utils.util import *\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Model\n",
    "model = Model(in_dim=n_mels, h_dim=512, out_dim=n_outputs)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31748b8c",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998d7f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 70356908\r\n",
      "-rw-rw-r-- 1 scpark scpark         0  7월 12 19:18 events.out.tfevents.1689157120.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark         0  7월 12 19:18 events.out.tfevents.1689157107.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark     76567  6월 24 20:47 events.out.tfevents.1687555677.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 20:39 save_133000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 20:29 save_132000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 20:18 save_131000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 20:07 save_130000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 19:56 save_129000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 19:45 save_128000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 19:34 save_127000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 19:23 save_126000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 19:12 save_125000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 19:01 save_124000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 18:50 save_123000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 18:39 save_122000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 18:28 save_121000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 18:17 save_120000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 18:06 save_119000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 17:55 save_118000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 17:44 save_117000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 17:33 save_116000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 17:22 save_115000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 17:11 save_114000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 16:59 save_113000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 16:48 save_112000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 16:37 save_111000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 16:26 save_110000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 16:15 save_109000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 16:04 save_108000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 15:53 save_107000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 15:41 save_106000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 15:30 save_105000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 15:19 save_104000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 15:08 save_103000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 14:57 save_102000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 14:46 save_101000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 14:35 save_100000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 14:24 save_99000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 14:12 save_98000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 14:01 save_97000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 13:50 save_96000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 13:39 save_95000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 13:28 save_94000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 13:17 save_93000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 13:06 save_92000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 12:54 save_91000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 12:43 save_90000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 12:32 save_89000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 12:21 save_88000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 12:10 save_87000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 11:59 save_86000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 11:47 save_85000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 11:36 save_84000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 11:25 save_83000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 11:14 save_82000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 11:03 save_81000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 10:52 save_80000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 10:40 save_79000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 10:29 save_78000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 10:18 save_77000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 10:07 save_76000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 09:56 save_75000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 09:45 save_74000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 09:33 save_73000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 09:22 save_72000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 09:11 save_71000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 09:00 save_70000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 08:49 save_69000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 08:38 save_68000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 08:26 save_67000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 08:15 save_66000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 08:04 save_65000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 07:53 save_64000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 07:42 save_63000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 07:31 save_62000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 07:20 save_61000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 07:08 save_60000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 06:57 save_59000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 06:46 save_58000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741441  6월 24 06:35 save_57000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 06:27 save_56389\r\n",
      "-rw-rw-r-- 1 scpark scpark     55540  6월 24 06:27 events.out.tfevents.1687520344.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 06:23 save_56000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 06:13 save_55000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 06:02 save_54000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 05:52 save_53000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 05:41 save_52000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 05:31 save_51000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 05:20 save_50000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 05:09 save_49000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 04:59 save_48000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 04:48 save_47000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 04:38 save_46000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 04:27 save_45000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 04:17 save_44000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 04:06 save_43000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 03:55 save_42000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 03:45 save_41000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 03:35 save_40000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 03:24 save_39000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 03:14 save_38000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 03:03 save_37000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 02:52 save_36000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 02:42 save_35000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 02:31 save_34000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 02:21 save_33000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 02:15 save_32496\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 02:10 save_32000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 02:00 save_31000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 01:50 save_30000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 01:39 save_29000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 01:29 save_28000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 01:19 save_27000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 01:08 save_26000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 00:57 save_25000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 00:47 save_24000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 00:36 save_23000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 00:26 save_22000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 00:16 save_21000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 24 00:05 save_20000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 23:55 save_19000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 23:44 save_18000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 23:34 save_17000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 23:24 save_16000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 23:13 save_15000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 23:03 save_14000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 22:52 save_13000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 22:42 save_12000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 22:32 save_11000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 22:22 save_10000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 22:11 save_9000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 22:01 save_8000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 21:50 save_7000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 21:40 save_6000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 21:30 save_5000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 21:20 save_4000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 21:10 save_3000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 21:00 save_2000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 20:49 save_1000\r\n",
      "-rw-rw-r-- 1 scpark scpark 529741121  6월 23 20:39 save_0\r\n",
      "-rw-rw-r-- 1 scpark scpark       808  6월 23 20:37 events.out.tfevents.1687519704.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark       131  6월 23 20:27 events.out.tfevents.1687519593.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark       466  6월 23 20:25 events.out.tfevents.1687519057.GPUSVR01\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded /data/scpark/save/lips/train06.23-1/save_133000\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lips/train06.23-1/'\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if True:\n",
    "    step, model, _, optimizer = load(save_dir, 133000, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d7b3c",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8aa62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_6_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_7_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_001_9_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_10_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_6_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_7_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_002_9_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_10_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_11_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_12_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_003_9_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_10_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_1_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_2_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_3_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_4_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_5_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_6_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_7_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_8_iPhone_raw.npy\n",
      "/data/speech/digital_human/preprocessed/MH_ARKit_004_9_iPhone_raw.npy\n",
      "36 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data.arkit_dataset import LipsDataset, CombinedDataset, CombinedCollate\n",
    "\n",
    "root_dir = '/data/speech/digital_human/preprocessed/'\n",
    "files = sorted([os.path.join(root_dir, file) for file in os.listdir(root_dir)])\n",
    "print(len(files))\n",
    "\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    dataset = LipsDataset(file, n_mels, n_frames)\n",
    "    if '_10_' in file:\n",
    "        test_datasets.append(dataset)\n",
    "    else:\n",
    "        train_datasets.append(dataset)\n",
    "print(len(train_datasets), len(test_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc7cac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(CombinedDataset(train_datasets), \n",
    "                                           num_workers=16, shuffle=True, batch_size=32, collate_fn=CombinedCollate())\n",
    "test_loader = torch.utils.data.DataLoader(CombinedDataset(test_datasets), \n",
    "                                          num_workers=10, shuffle=True, batch_size=10, collate_fn=CombinedCollate())\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03238ce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "isnan = False\n",
    "while True:\n",
    "    if isnan:\n",
    "        break\n",
    "    for batch in train_loader:\n",
    "        inputs = torch.Tensor(batch['mel']).transpose(1, 2).to(device)\n",
    "        targets = torch.Tensor(batch['blend']).transpose(1, 2).to(device)\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs, targets)\n",
    "        \n",
    "        print(step)\n",
    "        loss = 0\n",
    "        for key in outputs.keys():\n",
    "            if 'loss' in key:\n",
    "                loss += outputs[key]\n",
    "                print(key, outputs[key].item())\n",
    "        if torch.isnan(loss):\n",
    "            isnan = True\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(step, loss.item())\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            writer.add_scalar('train_loss', loss.item(), step)\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            display.clear_output()\n",
    "            \n",
    "            losses = []\n",
    "            for i, batch in enumerate(test_loader):\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                    \n",
    "                inputs = torch.Tensor(batch['mel']).transpose(1, 2).to(device)\n",
    "                targets = torch.Tensor(batch['blend']).transpose(1, 2).to(device)\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs, targets)\n",
    "                    \n",
    "                loss = 0\n",
    "                for key in outputs.keys():\n",
    "                    if 'loss' in key:\n",
    "                        loss += outputs[key]\n",
    "                print('test :', i, loss.item())\n",
    "                losses.append(loss)        \n",
    "            \n",
    "            test_loss = torch.stack(losses).mean().item()\n",
    "            print('test_loss :', test_loss)\n",
    "            writer.add_scalar('test_loss', test_loss, step)\n",
    "            \n",
    "#             plt.figure(figsize=[18, 4])\n",
    "#             librosa.display.specshow(targets[0].data.cpu().numpy(), cmap='magma')\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.figure(figsize=[18, 4])\n",
    "#             librosa.display.specshow(outputs['y_pred'][0].data.cpu().numpy(), cmap='magma')\n",
    "#             plt.show()\n",
    "            \n",
    "#             for i in [20, 37]:\n",
    "#                 plt.figure(figsize=[18, 2])\n",
    "#                 plt.title(str(i))\n",
    "#                 plt.plot(targets[0].data.cpu().numpy()[i])\n",
    "#                 plt.plot(outputs['y_pred'][0].data.cpu().numpy()[i])\n",
    "#                 plt.show()\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            save(save_dir, step, model, None, optimizer)\n",
    "    \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c85fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1166d67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce39d126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste2",
   "language": "python",
   "name": "ste2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
